#+title: é›¢æ•£éš ã‚Œç©ºé–“ã§ã®è¨˜å·æ¨è«–
#+include: "head.org"
#+LINK: img file:img/%s
#+LINK: png file:img/%s.png
#+LINK: jpg file:img/%s.jpg
#+LINK: svg file:img/%s.svg
#+LINK: spng file:img/static/%s.png
#+LINK: sjpg file:img/static/%s.jpg
#+LINK: ssvg file:img/static/%s.svg
#+LINK: sgif file:img/static/%s.gif

#+begin_outline-text-1
#+begin_center

#+begin_larger
Masataro Asai

The University of Tokyo
#+end_larger

20+ min
#+end_center

#+begin_note
#+begin_alignright
Made by guicho2.71828 (Masataro Asai)
#+end_alignright
#+end_note
#+end_outline-text-1

* Overview

#+begin_center
#+begin_xlarge
*Backgrounds*

*Latplan Architecture*

*State AutoEncoder (SAE)*
#+end_xlarge

break

#+begin_xlarge
*AMA_2 Overview*

*Action AutoEncoder (AAE)*

*Action Discriminator (AD)*
#+end_xlarge
#+end_center

* Overview

#+begin_center
#+begin_xlarge
*/Backgrounds/*

*Latplan Architecture*

*State AutoEncoder (SAE)*
#+end_xlarge

break

#+begin_xlarge
*AMA_2 Overview*

*Action AutoEncoder (AAE)*

*Action Discriminator (AD)*
#+end_xlarge
#+end_center

* èƒŒæ™¯ -- AIãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°

 #+begin_container-fluid
 #+begin_row-fluid
 #+begin_span6
 [[png:astro/1]]
 #+end_span6
 #+begin_span6
 [[png:rescue/1]]
 #+end_span6
 #+end_row-fluid
 #+end_container-fluid

** èª°?

 #+begin_container-fluid
 #+begin_row-fluid
 #+begin_span6
 [[png:astro/1]]
 #+end_span6
 #+begin_span6
 [[png:rescue/1]]
 #+end_span6
 #+end_row-fluid
 #+end_container-fluid

  #+begin_resume
  and let me introduce these robots.
  the guy in the left is astro boy.
  #+end_resume

*** èª°?

 #+begin_container-fluid
 #+begin_row-fluid
 #+begin_span6
 [[png:astro/2]]
 #+end_span6
 #+begin_span6
 [[png:rescue/1]]
 #+end_span6
 #+end_row-fluid
 #+end_container-fluid

 #+begin_resume
 as you know, he is a famous manga superhero invented by tezuka osamu in 50s,
 #+end_resume

*** èª°?

  #+begin_container-fluid
  #+begin_row-fluid
  #+begin_span6
  [[png:astro/final]]
  #+end_span6
  #+begin_span6
  [[png:rescue/1]]
  #+end_span6
  #+end_row-fluid
  #+end_container-fluid

 #+begin_resume
 and he can think, hear, speak, act. he also has emotions.
 #+end_resume

*** èª°?

  #+begin_container-fluid
  #+begin_row-fluid
  #+begin_span6
  [[png:astro/final]]
  #+end_span6
  #+begin_span6
  [[png:rescue/2]]
  #+end_span6
  #+end_row-fluid
  #+end_container-fluid

 #+begin_resume
  in contrast, the guy in the right is a real robot that is actually in use @ fukuoka prefecture for the rescue purpose..
  his name is t-52 enryu, developped by a japanese company temzak.
  he is huge and powerful -- about 4 meters in height and can carry things which is as heavy as 500kg.
  well, so, in a sense, he is also a superhero in the real disastrous situation.
 #+end_resume

*** èª°?

  #+begin_container-fluid
  #+begin_row-fluid
  #+begin_span6
  [[png:astro/final]]
  #+end_span6
  #+begin_span6
  [[png:rescue/3]]
  #+end_span6
  #+end_row-fluid
  #+end_container-fluid

 #+begin_resume
 but does he have feelings or can he think? can he even move around by his own?
 #+end_resume

*** èª°?

  #+begin_container-fluid
  #+begin_row-fluid
  #+begin_span6
  [[png:astro/final]]
  #+end_span6
  #+begin_span6
  [[png:rescue/final]]
  #+end_span6
  #+end_row-fluid
  #+end_container-fluid

 #+begin_resume
 no. it requires full human intervention --- it is indeed operated by a
 driver who gets in or by a remote control. it is more like a
 super-sophisticated shovel car.
 #+end_resume

** å®Ÿéš›ã®å¤§è¦æ¨¡ç½å®³ã§ã¯éå®Ÿç”¨çš„ --- æ“ç¸¦å£«ãŒè¶³ã‚Šãªã„!              :noexport:

 #+begin_container-fluid
 #+begin_row-fluid
 #+begin_span2
 [[png:rescue]]
 [[png:rescue]]
 [[png:rescue]]
 [[png:silent]]
 #+end_span2
 #+begin_span10
 [[jpg:static/tsunami]]
 #+end_span10
 #+end_row-fluid
 #+end_container-fluid

 #+begin_larger
 #+begin_alignright
 + ãã®ã¾ã¾ã§ã¯å½¹ã«ç«‹ãŸãªã„!
 #+end_alignright
 #+end_larger

 #+begin_resume
 now the problem is : it's ok in small accidents but is impractical in the real, massive 
 natural disaster which frequently occurs in japan.
 the key resource is human ---
 these special purpose vehicles require human intervention,
 thus they are useless without trained operators.
 #+end_resume

*** æ“ç¸¦å£«ã‚’å¢—ã‚„ã›ãªã„ -- human resource and training

 #+begin_container-fluid
 #+begin_row-fluid
 #+begin_span4
  [[png:rescue/1]]
 #+end_span4
 #+begin_span8

   + âœ˜ /æ™‚é–“/ ãŒã‹ã‹ã‚‹ :: è¨“ç·´ã« ï¼100æ™‚é–“, *å¿…è¦ãªæ™‚ã ã‘å¢—ã‚„ã™* ã®ã¯ä¸å¯èƒ½
   + âœ˜ /ï¿¥ï¿¥ï¿¥ï¿¥/ ãŒã‹ã‹ã‚‹ :: è¨“ç·´å®˜ã€è¨“ç·´å ´æ‰€ã€è¨“ç·´ç”¨å…·
   + âœ˜ æŠ€è¡“ã¯ /ç¶­æŒãŒé‡è¦/ :: å®šæœŸçš„ãªå†è¨“ç·´ã€é•·æœŸçš„ã‚³ã‚¹ãƒˆã€ã•ã‚‰ãªã‚‹ãƒãƒ‹ãƒ¼
   + âœ˜ å¹³æ™‚ã¯ /ç„¡é§„/ ãªæŠ€è¡“ :: æ™®æ®µã¯æ„å‘³ãŒãªã„ -- ç„¡é§„ãªãƒãƒ‹ãƒ¼!
 #+end_span8
 #+end_row-fluid
 #+end_container-fluid

 #+begin_resume
 in a natural disaster, we need as many experienced operators as possible.
 however, it is virtually impossible due to several reasons. 

 first, training takes time.
 it is impossible to quickly increase the number of operators as needed, at the time of disaster.

 second, the money matters.
 training a person costs a lot of money, including: the cost of maintaining
 a training center, the cost of additional vehicles for training, the cost
 of training the trainers, wages for trainers, etc.

 third, skills need to be updated and maintained.
 you know, how about preparing the large number of operators in advance?
 no, the society cannot torelate the cost of keep training them.
 operators may lose the skills and skills may become outdated.

 finally, in a normal situation, those skills are useless.
 it forces the society to waste a great amount of extra money.
 #+end_resume

** è‡ªå¾‹è¡Œå‹•ã®ãŸã‚ã®è‡ªå‹•ãƒ—ãƒ©ãƒ³ãƒŠ (â‰  ãƒ¢ãƒ¼ã‚¿åˆ¶å¾¡)

 [[png:planning/1]]

 #+begin_resume
 ç ”ç©¶ãƒ†ãƒ¼ãƒã®ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã¯ã€ãƒ­ãƒœãƒƒãƒˆã«ã€äººé–“ã®åŠ©ã‘ã‚’å€Ÿã‚Šãšã€ã„ã‹ã«è‡ªå¾‹ã—ã¦è¡Œå‹•ã•ã›ã‚‹ã‹ã‚’æ‰±ã„ã¾ã™ã€‚
 ã“ã‚Œã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—ãŸãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°å•é¡Œã¯ã€å…·ä½“çš„ãªè¡Œå‹•ã®åˆ—ã‚’æ±‚ã‚ã‚‹ çµ„åˆã›æœ€é©åŒ–å•é¡Œã§ã™ã€‚

 ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°å•é¡Œã®ã‚¿ã‚¹ã‚¯ã¯ã€
 ã‚»ãƒ³ã‚µãƒ¼ã‹ã‚‰åˆæœŸçŠ¶æ…‹ã¨ã‚´ãƒ¼ãƒ«ã‚’å—ã‘å–ã£ã¦ã€è¢«ç½è€…ã‚’åŠ©ã‘ã‚‹æ­£ã—ã„æ‰‹é †ã‚’å‡ºåŠ›ã™ã‚‹ã“ã¨ã§ã™ã€‚

 ãŸã¨ãˆã°ã€ã“ã®å›³ã§ã¯ç”·æ€§ãŒç“¦ç¤«ã«åŸ‹ã¾ã£ã¦åŠ©ã‘ã‚’æ±‚ã‚ã¦ã„ã¾ã™ã€‚
 ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ã®ã‚ã‚‹ãƒ­ãƒœãƒƒãƒˆã¯ã€ã‚³ãƒ¬ã«å¯¾ã—ã¦ã€Œç”·æ€§ã‚’åŠ©ã‘ã‚ˆã€ã¨ã„ã†å¤§ã¾ã‹ãªæŒ‡ç¤ºã‚’å—ã‘ã¾ã™ã€‚
 #+end_resume

** è‡ªå¾‹è¡Œå‹•ã®ãŸã‚ã®è‡ªå‹•ãƒ—ãƒ©ãƒ³ãƒŠ (â‰  ãƒ¢ãƒ¼ã‚¿åˆ¶å¾¡)

 [[png:planning/2]]

 #+begin_resume
 æŒ‡ç¤ºã®å†…å®¹ã«ã¯ã€å›³ã®ã‚ˆã†ã«åˆæœŸçŠ¶æ…‹ã¨ã‚´ãƒ¼ãƒ«ã€è¨±å¯ã•ã‚ŒãŸè¡Œå‹•ã®ãƒªã‚¹ãƒˆãŒå…¥ã£ã¦ã„ã¾ã™ã€‚
 ãƒ­ãƒœãƒƒãƒˆã¯ã€è‡ªå‹•ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šã€äººé–“ã®ä»£ã‚ã‚Šã«é©åˆ‡ãªè¡Œå‹•ã‚’çµ„ã¿ç«‹ã¦ã¦ã€ã‚´ãƒ¼ãƒ«ã‚’è‡ªå‹•ã§é”æˆã—ã¾ã™ã€‚
 #+end_resume

** è‡ªå¾‹è¡Œå‹•ã®ãŸã‚ã®è‡ªå‹•ãƒ—ãƒ©ãƒ³ãƒŠ (â‰  ãƒ¢ãƒ¼ã‚¿åˆ¶å¾¡)

 [[png:planning/final]]

 #+begin_resume
 ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã¯æ±ç”¨ãªæ çµ„ã¿ãªã®ã§ã€ç½å®³æ•‘åŠ©ä»¥å¤–ã«ã‚‚æ§˜ã€…ãªå•é¡Œã«é©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
 ç¾å®Ÿã®å¿œç”¨ä¾‹ã§ã¯ã€Œå®‡å®™æ¢æŸ»æ©Ÿé‹è¡Œå•é¡Œã€ã‚„ã€Œä¼æ¥­ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è„†å¼±æ€§å•é¡Œã€ã‚‚è¡¨ç¾ã§ãã¾ã™ã€‚

 ã“ã®ã‚ˆã†ã«ã€ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã¯ã€é›£ã—ã„å•é¡Œã‚’æ±ç”¨æ€§ã‚’å¤±ã‚ãšã«è§£ãã“ã¨ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚
 #+end_resume

** AIãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã® */Killer App/*                                 :noexport:


#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN7
#+BEGIN_LARGER
+ äººãŒé«˜ä¾¡orä¸å¯èƒ½ãªä½œæ¥­ :: åŸç™º, å®‡å®™ç©ºé–“, ç«æ˜Ÿ, æ·±æµ·
+ æ­£ã—ã•ã¨æœ€é©æ€§ã®ç†è«–ä¿è¨¼ãŒå¿…è¦ãªãƒŸãƒƒã‚·ãƒ§ãƒ³ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚·ã‚¹ãƒ†ãƒ  :: 
     è£½é€ ã‚·ã‚¹ãƒ†ãƒ ã€é‹é€ (æ™‚é–“=ãŠé‡‘)

     äººå·¥è¡›æ˜Ÿ (ç‡ƒæ–™ä½¿ã„ãã‚Œã°é‹ç”¨çµ‚äº†)

     é–“é•ã£ãŸè§£ã¯è¨±ã•ã‚Œãªã„
+ æ€è€ƒéç¨‹ã‚’èª¬æ˜å¯èƒ½ãªã‚·ã‚¹ãƒ†ãƒ  :: 
     ãƒ¬ã‚¹ã‚­ãƒ¥ãƒ¼ãƒ»å®‡å®™èˆ¹ (äººé–“ã®å®‰å…¨ãŒã‹ã‹ã£ã¦ã„ã‚‹)
#+END_LARGER

# [[sjpg:martian]]

#+END_SPAN7
#+BEGIN_SPAN5

[[sjpg:gravity-m]]

#+END_SPAN5
#+END_ROW-FLUID
#+END_CONTAINER-FLUID



** AIã¨è‡ªå‹•ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚° ã®ä½ç½®ã¥ã‘ -- /ç†è«–/ ã¨ /å®Ÿå¿œç”¨/ ã®ä¸­é–“    :noexport:

 ç·‘ã¯ /ç†è«–/ ã€ã‚ªãƒ¬ãƒ³ã‚¸ã¯ /å®Ÿå¿œç”¨/ ã€ AI ã¯ãã®æ©‹æ¸¡ã— (ã©ã‚Œã¨ã‚‚ã‹ã¶ã‚‰ãªã„éƒ¨åˆ†ã‚‚ã‚ã‚‹)

 #+BEGIN_RESUME
 Automated Planning is a branch of Aritificial Intelligence. 

 It shares a lot of technology with Operations Research and Theoretical
 Computer Science, and is considered a bridge between pure theory and
 pure applications.
 #+END_RESUME

 [[png:planning-related-field]]

* å¤å…¸ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°å•é¡Œ (æ±ºå®šçš„,å®Œå…¨æƒ…å ±) -- Blocksworld            :noexport:

#+HTML: <embed src="img/plan.svg" type="image/svg+xml"  />

#+begin_larger
éå¤å…¸çš„ãªã•ã¾ã–ã¾ãªæ‹¡å¼µ
#+begin_alignright
(ä¸¦åˆ—ã‚¢ã‚¯ã‚·ãƒ§ãƒ³,POMDP,HTN... AIã®æ•™ç§‘æ›¸ã‚’å‚ç…§)
#+end_alignright
#+end_larger

** ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ = æ¡ä»¶ä»˜ãçŠ¶æ…‹é·ç§»

#+begin_center
#+begin_xlarge
ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ (move ?x ?y)
#+end_xlarge
#+end_center

#+BEGIN_CENTER
*?X*, *?Y* : å¤‰æ•°ã€‚ å€¤ *BLOCK-A*, *BLOCK-B* ãªã©ã‚’é©ç”¨ã—ã¦ä½¿ã†

*æ¡ä»¶* ã¨ *åŠ¹æœ* ã§æ§‹æˆã•ã‚Œã‚‹
#+END_CENTER


#+begin_container-fluid
#+begin_row-fluid
#+begin_span7
#+begin_quote
*æ¡ä»¶* : å®Ÿè¡Œã«å¿…è¦ãªæ¡ä»¶ã‚’è¡¨ã™å‘½é¡Œ

ã€€(clear *?X*) : ç©ã¿æœ¨ *?X* ã®ä¸ŠãŒç©º

ã€€(clear *?Y*) : ç©ã¿æœ¨ *?Y* ã®ä¸Šã«ç©º

*åŠ¹æœ* : å‰å¾Œã®çŠ¶æ…‹ã® *å·®åˆ†* ã‚’è¡¨ã™å‘½é¡Œ

ã€€(on *?X* *?Y*) ã‚’ *è¿½åŠ * : *?Y* ã®ä¸Šã¯ *?X*

ã€€(clear *?Y*) ã‚’ *å‰Šé™¤*
#+end_quote
#+end_span7
#+begin_span5
#+begin_src lisp
(:action move
 :parameters (?X ?Y)
 :preconditions
   (and (clear ?X)   ; (1)
        (clear ?Y))  ; (2)

 :effect
   (and (on ?X ?Y)   ; (3)
        (not         ; (4)
         (clear ?Y))))
#+end_src
#+begin_alignright
#+begin_larger
ãƒ¢ãƒ‡ãƒªãƒ³ã‚°è¨€èª *PDDL* ã§è¨˜è¿°
#+end_larger
#+end_alignright
#+end_span5
#+end_row-fluid
#+end_container-fluid

** *PDDL* : Planning Domain Description Language                   :noexport:

International Planning Competition ã§ä½¿ã‚ã‚Œã¦ã„ã‚‹å…¥åŠ›å½¢å¼

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN2

#+END_SPAN2
#+BEGIN_SPAN8
#+BEGIN_SRC lisp
(:action move
 :parameters (?X ?Y)
 :preconditions
   (and (clear ?X)   ; (1)
        (clear ?Y))  ; (2)

 :effect
   (and (on ?X ?Y)   ; (3)
        (not         ; (4)
         (clear ?Y))))
#+END_SRC
#+END_SPAN8
#+BEGIN_SPAN2

#+END_SPAN2
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

** ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚° = ã‚°ãƒ©ãƒ•æ¢ç´¢

*ãƒãƒ¼ãƒ‰* : çŠ¶æ…‹ = å‘½é¡Œã®é›†åˆ â‡’ =(on A B)=, =(clear A)= ãªã©

*è¾º*     : ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ â‡’ =(move A B)= ç­‰

[[png:graph]]

# #+BEGIN_CONTAINER-FLUID
# #+BEGIN_ROW-FLUID
# #+BEGIN_SPAN6
# # + ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯æ¢ç´¢ A*
# # + State-of-the-Art *1
# #+END_SPAN6
# #+BEGIN_SPAN6
# # #+attr_html: :width 50%
# #+END_SPAN6
# #+END_ROW-FLUID
# #+END_CONTAINER-FLUID

#+BEGIN_NOTE
*1 [Helmert, 2006] [Richter, 2010]
#+END_NOTE
  
** Q. ã„ã¾ */ã¯ã‚„ã‚Š/* ã®Deep Learningã¨ã®é•ã„ã¯?                   :noexport:

 A. ãƒ¬ã‚¤ãƒ¤ãŒé•ã†

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN6
 *æ©Ÿæ¢°å­¦ç¿’ãƒ»Neural Networks* 
 
 for *èªè­˜ãƒ»åå°„*
 + å…¥åŠ› ã¯ *Subsymbolic* (é€£ç¶šå€¤)
   
   ç”»åƒã€éŸ³å£°ã€éæ§‹é€ åŒ–ãƒ†ã‚­ã‚¹ãƒˆ: 
 + *æ„Ÿè¦šçš„çŸ¥èƒ½*:
   
   ã€€ */åå¿œ/, /ç›´å¾Œ/ ã®è¡Œå‹•ã®æ±ºå®š*
   #+BEGIN_SMALLER
   *ãƒ‘ãƒ–ãƒ­ãƒ•ã®çŠ¬* : é¤Œã‚’èªçŸ¥â†’ã‚ˆã ã‚Œ

   *è‡ªå‹•é‹è»¢* : èµ¤ä¿¡å·,äºº â†’ æ­¢ã¾ã‚‹.

   *ç¿»è¨³* : æ–‡ç«  â†’ æ–‡ç« 

   *å›²ç¢å±€é¢ã®è©•ä¾¡é–¢æ•°* : å±€é¢ â†’ å‹ç‡
   #+END_SMALLER
   #+BEGIN_LARGER
   â˜º åŠ¹ç‡ã‚ˆã 1-to-1 mapping
   
   â˜¹ å˜ç´”ä½œæ¥­
   #+END_LARGER
 #+END_SPAN6
 #+BEGIN_SPAN6
 *æ¨è«–ãƒ»æ¢ç´¢*

 for *ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ãƒ»ã‚²ãƒ¼ãƒ ãƒ»å®šç†è¨¼æ˜*
 + å…¥å‡ºåŠ›ã¯ *Symbolic*
   
   è«–ç† ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ ãƒ«ãƒ¼ãƒ«
 + *è«–ç†ãƒ»æ¨è«–ã«ã‚ˆã‚‹çŸ¥èƒ½:*

   ã€€ */æœªæ¥ã«æ¸¡ã‚‹/ æˆ¦ç•¥ã®æ±ºå®š*
   
   ã€€ (æˆ¦ç•¥ = è¡Œå‹•ã® *åˆ—ã‚„æœ¨*)
   #+BEGIN_SMALLER
   *ãƒ¬ã‚¹ã‚­ãƒ¥ãƒ¼ãƒ­ãƒœ* : ã‚´ãƒ¼ãƒ« = è¢«ç½è€…ç”Ÿå­˜

   *è¨¼æ˜å™¨* : ã‚´ãƒ¼ãƒ« = QED

   *ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©* : å‘½ä»¤åˆ—ã®ç”Ÿæˆ
   
   *å›²ç¢,å°†æ£‹* : ã‚´ãƒ¼ãƒ« = å‹åˆ©
   #+END_SMALLER
   #+BEGIN_LARGER
   â˜º é †åºåˆ¶ç´„+è¤‡é›‘ãªä½œæ¥­
   #+END_LARGER
 #+END_SPAN6
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

+ AlphaGo = Subsymbolic (DLNNã«ã‚ˆã‚‹è©•ä¾¡é–¢æ•°) + Symbolic (MCTSã«ã‚ˆã‚‹æ¢ç´¢)

** æ—¢å­˜ã®æœ‰åã‚·ã‚¹ãƒ†ãƒ                                               :noexport:

AlphaGo = Subsymbolic (NNã«ã‚ˆã‚‹è©•ä¾¡é–¢æ•°) + Symbolic (MCTSã«ã‚ˆã‚‹æ¢ç´¢)
+ ãŸã ã— *ãƒ‰ãƒ¡ã‚¤ãƒ³ä¾å­˜* -- å›²ç¢ã«ç‰¹åŒ–, "ãƒã‚¹ç›®"ã‚„"çŸ³"ã¨ã„ã£ãŸæ¦‚å¿µã‚’ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰
+ *è†¨å¤§ãªæ£‹è­œãŒå¿…è¦* --- é‹ç”¨ãƒ‡ãƒ¼ã‚¿ãŒãªã„ç’°å¢ƒ(e.g.ç«æ˜Ÿ)ã«ã¯é©ç”¨ä¸èƒ½
+ */äººã£ã¦æ¨¡ç¯„è§£ç­”ãŒãªã„ã¨è¡Œå‹•ã§ãã¾ã›ã‚“ã‹?/* *çœŸã®è‡ªå¾‹æ©Ÿæ¢°ã¯å‰ä¾‹ç„¡ã—ã§ã‚‚è¡Œå‹•å¯èƒ½*

DQN = Subsymbolic (DLNN) + å¼·åŒ–å­¦ç¿’ (DLNN)

æ§˜ã€…ãª Atari Game ã«ã¤ã‹ãˆã‚‹æ±ç”¨ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ (Invader, Packmanâ€¦) ã ãŒ
+ RLã®Acting: å­¦ç¿’ã—ãŸpolicyã«å¾“ã£ã¦greedyã«è¡Œå‹•
+ Atariã‚²ãƒ¼ãƒ ã¯ *è„Šé«„åå°„ã§ç”Ÿãæ®‹ã‚‹ã“ã¨ãŒå¯èƒ½* â†’ *è¤‡é›‘ãªè«–ç†æ€è€ƒã¯ã„ã‚‰ãªã„!*
  
# å®Ÿéš› *Sokoban ãªã©è«–ç†æ€è€ƒã‚²ãƒ¼ãƒ ã§ã¯æ€§èƒ½ãŒæ‚ªã„* â†” å€‰åº«ç•ªã‚½ãƒ«ãƒ



* ã‚¹ãƒ©ã‚¤ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¤ãƒ«ãƒ‘ã‚ºãƒ« (a.k.a 8-puzzle)

#+begin_container-fluid
#+begin_center
#+begin_row-fluid
#+begin_span4
[[png:8puzzle-standard]]
Initial State
#+end_span4
#+begin_span4
[[png:8puzzle-standard-goal]]
Goal State
#+end_span4
#+begin_span4
[[sgif:8puzzle]]
#+end_span4
#+end_row-fluid
#+end_center
#+end_container-fluid

#+begin_alignright
+ *ã‚´ãƒ¼ãƒ«ã«åˆ°é”ã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ—=ãƒ—ãƒ©ãƒ³ã‚’æ¢ã™ã®ãŒç›®çš„*
#+end_alignright

** çŠ¶æ…‹

*çŠ¶æ…‹* ã¯ *ä¸€éšè¿°èªè«–ç†ã®å‘½é¡Œåˆ—* , ãƒ¢ãƒ‡ãƒªãƒ³ã‚°è¨€èª *PDDL* ã§è¡¨ã•ã‚Œã‚‹.

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
#+begin_quote
#+begin_smaller
/Empty(x_0, y_0)/

/Is(panel_6, x_1, y_0)/

/Up(y_0, y_1), Down(y_1, y_0).../

/Right(x_0, x_1), Left(x_0, x_1).../
#+end_smaller
#+end_quote
#+end_span6
#+begin_span6
#+begin_src lisp
(empty x0 y0)
(is panel6 x1 y0)
(up    y0 y1), (down y1 y0)...
(right x0 x1), (left x0 x1)...
#+end_src
#+end_span6
#+end_row-fluid
#+begin_center
#+begin_row-fluid
#+begin_span4
[[png:8puzzle-standard]]
Initial State
#+end_span4
#+begin_span4
[[png:8puzzle-standard-goal]]
Goal State
#+end_span4
#+begin_span4
[[sgif:8puzzle]]
#+end_span4
#+end_row-fluid
#+end_center
#+end_container-fluid

** çŠ¶æ…‹é·ç§» / ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

#+begin_container-fluid
#+begin_row-fluid
#+begin_span9
*ä¸Šã«ã‚¹ãƒ©ã‚¤ãƒ‰* ã‚’è¡¨ã™ãƒ«ãƒ¼ãƒ« â†’ *ã‚¢ã‚¯ã‚·ãƒ§ãƒ³*

#+begin_quote
+ *ä¸ŠãŒç©ºããªã‚‰* ä¸Šã«ã‚¹ãƒ©ã‚¤ãƒ‰å¯èƒ½ (*å‰ææ¡ä»¶*)

+ *åŠ¹æœ*: ä»Šã®å ´æ‰€ã¯ *ç©ºãã«ãªã‚Š*

+ ä¸Šã¯ *Â¬ç©ºã* ã«ãªã‚‹.
#+end_quote
#+end_span9
#+begin_span3
initial state
[[png:8puzzle-standard-tile7]]
#+end_span3
#+end_row-fluid
#+begin_row-fluid
#+begin_span12
+ *ä¸€éšè¿°èªè«–ç†*
  
  *When* /Empty(x, y_{old}) âˆ§ is(panel, x, y_{new}) âˆ§ up(y_{new}, y_{old})/ ;
  
  *then* /Â¬ Empty(x,y_{old}) âˆ§ Empty(x,y_{new}) âˆ§ Â¬ is(panel, x, y_{new}) .../

+ *PDDL Model* : ãƒ—ãƒ©ãƒ³ãƒŠã¸ã®å®Ÿéš›ã®å…¥åŠ›
  #+begin_src lisp
  (:action slide-up ...
   :precondition (and (empty ?x ?y-old) ...)
   :effects (and (not (empty ?x ?y-old)) (empty ?x ?y-new) ...))
  #+end_src

# #+begin_src lisp
# (:action move-up
#  :parameters (?x ?y-old ?y-new ?panel)
#  :precondition (and (empty ?x ?y-old)
#                     (up ?y-old ?y-new)
#                     (is ?panel ?x ?y-new))
#  :effects (and (not (empty ?x ?y-old))
#                (empty ?x ?y-new)
#                (not (is ?panel ?x ?y-new))
#                (is ?panel ?x ?y-old)))
# #+end_src
#+end_span12
#+end_row-fluid
#+end_container-fluid

# + 
#   #+begin_larger
#   #+begin_alignright
#   But *where does this representation come from?*
#   #+end_alignright
#   #+end_larger

** ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚° = ã‚°ãƒ©ãƒ•æ¢ç´¢

*ãƒãƒ¼ãƒ‰* : çŠ¶æ…‹ = å‘½é¡Œã®é›†åˆ â‡’ =(on A B)=, =(clear A)= ãªã©

*è¾º*     : ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ â‡’ =(move A B)= ç­‰

[[png:graph]]

# #+BEGIN_CONTAINER-FLUID
# #+BEGIN_ROW-FLUID
# #+BEGIN_SPAN6
# # + ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯æ¢ç´¢ A*
# # + State-of-the-Art *1
# #+END_SPAN6
# #+BEGIN_SPAN6
# # #+attr_html: :width 50%
# #+END_SPAN6
# #+END_ROW-FLUID
# #+END_CONTAINER-FLUID

#+BEGIN_NOTE
*1 [Helmert, 2006] [Richter, 2010]
#+END_NOTE
  
** è¨˜å·çš„ãƒ—ãƒ©ãƒ³ãƒŠã¯ */ç”»åƒãƒ™ãƒ¼ã‚¹ã®/* 8-puzzle ã‚’è§£ã‘ãªã„

#+begin_center
+ *ç¾åœ¨ã®è¨ˆç®—æ©Ÿ+ç¾åœ¨ã®ã‚½ãƒ«ãƒã¯ã€8ãƒ‘ã‚ºãƒ«ã‚’ã€PDDLã•ãˆã‚ã‚Œã°0.1ç§’ä»¥ä¸‹ã§æœ€é©ã«è§£ã‘ã‚‹ã€‚*
#+end_center

#+begin_container-fluid
#+begin_row-fluid
#+begin_span8
[[sjpg:puzzle]]
#+end_span8
#+begin_span4
+ 
   #+begin_center
   *ã—ã‹ã—*

   */PDDL/*

   */ãƒ¢ãƒ‡ãƒ«ãŒ/*

   */ç„¡ã„!!!/*
#+end_center
#+end_span4
#+end_row-fluid
#+end_container-fluid

** çŸ¥è­˜ç²å¾—ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ (Cullen, 1988):

#+begin_quote
*ç¾å®Ÿã®å•é¡Œ* ã‚’ *è¨˜å·çš„ã‚·ã‚¹ãƒ†ãƒ * ã«è§£ã‹ã›ã‚‹ãŸã‚ã€
*å•é¡Œã‚’äººé–“ãŒè¨˜å·ãƒ¢ãƒ‡ãƒ«åŒ–* ã™ã‚‹ã®ã«ã‹ã‹ã‚‹ã‚³ã‚¹ãƒˆã€‚
#+end_quote

#+begin_container-fluid
#+begin_row-fluid
#+begin_span12
+ *ã„ã¾ã‚ã‚‹ç”»åƒç‰ˆ8ãƒ‘ã‚ºãƒ«ã§ã¯ã€ï¼’ã¤ã®ä½œæ¥­ãŒå¿…è¦*:
#+end_span12
#+end_row-fluid
#+begin_row-fluid
#+begin_span6
+ *1. ã‚·ãƒ³ãƒœãƒ«ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°:*

  #+begin_center
  #+begin_larger
  */ã‚·ãƒ³ãƒœãƒ«/ = ç‹¬ç«‹ã—ãŸè¦ç´ *
  #+end_larger
  #+end_center
  
  ã‚·ãƒ³ãƒœãƒ«ã«ã¯ *ç¨®é¡* ãŒã‚ã‚‹ã€‚
  #+begin_smaller
  | ç¨®é¡         | ä¾‹                           |
  |--------------+------------------------------|
  | ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ | *panel7*, *x_0*, *y_0* ...   |
  | è¿°èª         | (*empty* ?x ?y)              |
  | å‘½é¡Œå¤‰æ•°     | *p_28* = (empty x_0 y_0)     |
  | ã‚¢ã‚¯ã‚·ãƒ§ãƒ³   | (*slide-up* panel_7 x_0 y_1) |
  #+end_smaller
#+end_span6
#+begin_span6
+ *2. ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã®ç²å¾—(AMA):*
  
  (Action Model Acquisition)

  #+begin_center
  #+begin_larger
  *ç’°å¢ƒã‚’å­¦ç¿’ã—ã€ã‚·ãƒ³ãƒœãƒ«ã§èª¬æ˜ã™ã‚‹.*
  #+end_larger
  #+end_center
  
  ã€€

  #+begin_center
  *When* /Empty(x, y_{old}) âˆ§ .../ ;

  *Then* /Â¬Empty(x,y_{old}) âˆ§/ ...
  #+end_center

#+begin_center
+ 
  #+begin_larger
  *ã“ã®ï¼’ã¤ã‚’åŒæ™‚ã«è§£æ±ºã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’ææ¡ˆã—ã¾ã™ã€‚*
  #+end_larger
#+end_center

#+end_span6
#+end_row-fluid
#+end_container-fluid

# #+begin_note
# The knowledge acquisition bottleneck: time for reassessment? : Cullen, J and Bryman, A Expert Syst. Vol 5 No 3 (August 1988) pp 216-225
# #+end_note

* Latent-Space Planner (*/Latplan/*)

#+begin_larger
 (*/Accepted/* in AAAI-2018)
#+end_larger

[[png:latplanlogo]]

* Survey of Exisiting Action Model Acquisition Techniques          :noexport:

#+begin_xlarge
Survey of Exisiting Action Model Acquisition Techniques
#+end_xlarge

ã€€

#+begin_alignright
i.e. Systems that find action models
#+end_alignright

** Limitations of Existing Systems                                 :noexport:

#+begin_xlarge
#+begin_center
So far, ALL existing AMA systems require */symbolic / near-symbolic, accurate state inputs/* and/or */discrete action labels/*.
#+end_center
#+end_xlarge

#+begin_alignright
i.e. They need symbols to find an action model
#+end_alignright

** So far, ALL existing AMA systems require */symbolic inputs/*

ARMS (Yang AIJ07)
LOCM (ICAPS09)
Argall (AIJ09)
Mourao (UAI12)

All taking the *symbolic* inputs to find the *action models*

[[spng:locm]]

** Framer (ICAPS17)                                                :noexport:

*Near-Symbols* : Parses natural language sentences with a *clear grammatical structure*.


#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
[[spng:framer]]
#+end_span6
#+begin_span6
+ Alleviates the burden of domain experts, but *still requires human*
+ Not handling "Natural Language":
  
  #+begin_quote
  Pick up that parcel over there ... yeah, it has a label on it, it says Parcel1, you can see
  it from here, the Location B. Then put it in the car, I mean the truck, the red one.
  #+end_quote
#+end_span6
#+end_row-fluid
#+end_container-fluid

** Konidaris, Kaelbring (AAAI14, IJCAI15)                          :noexport:

"Constructing Symbolic Representations for High-Level Planning" (AAAI14)

+ What it does :: Converting a *Semi-MDP Model* to a *PDDL Model* by set-theoretic representation
                  
                  i.e. *Model-to-Model* conversion, not *generating a model from the scratch*
+ Semi-MDP contains Action Labels :: =move= and =interact= (Playroom)
+ Sensor inputs are structured (Labels for "State Variable" are known) :: 

     x/y-distance, light level, whether a monkey cries
     
     â†’ Each sensor has a distinct meaning (no overwrap)

# + Low-dimensional, accurate input :: 33 vars (Playroom), 9 vars (Treasure), no noise
#      
#      Although IJCAI15 shows "visual depiction", it is not used by the system

** Learning from Video for Board Game (Bardu ICRA10; Kaiser AAAI12; Kirk 16) :noexport:

*Handles Images, but with strong assumptions (almost symbol)* e.g.

#+begin_quote
Tic-Tac-Toe with *Ellipse Detectors* (Bardu 10)
     
â†’ Almost immediately provides propositions

â†’ Also, Domain-dependent ("3x3 grid" "Ellipse" are hard-coded)
#+end_quote

* å•é¡Œè¨­å®š

#+begin_center
#+begin_xlarge
Latplan ã®å•é¡Œè¨­å®š
#+end_xlarge
#+end_center

** äº‹å‰çŸ¥è­˜ãªã— ç”»åƒå…¥åŠ›ã®ã¿ã§8ãƒ‘ã‚ºãƒ«ã‚’è§£ããƒ—ãƒ­ã‚°ãƒ©ãƒ 

*äº‹å‰çŸ¥è­˜ãªã—* : ã€Œ9ãƒã‚¹ã‚ã‚‹ã€ã€Œå‹•ããƒ‘ãƒãƒ«ã€ãªã©äººã®ä¸ãˆãŸ *ãƒ©ãƒ™ãƒ«ãƒ»ã‚·ãƒ³ãƒœãƒ«ãªã—*

[[sjpg:puzzle]]

** */äº‹å‰çŸ¥è­˜ãªã—/* ç”»åƒå…¥åŠ›ã®ã¿ã§8ãƒ‘ã‚ºãƒ«ã‚’è§£ããƒ—ãƒ­ã‚°ãƒ©ãƒ 

*äº‹å‰çŸ¥è­˜ãªã—* : ã€Œ9ãƒã‚¹ã‚ã‚‹ã€ã€Œå‹•ããƒ‘ãƒãƒ«ã€ãªã©äººã®ä¸ãˆãŸ *ãƒ©ãƒ™ãƒ«ãƒ»ã‚·ãƒ³ãƒœãƒ«ãªã—*

[[sjpg:puzzle]]

** äº‹å‰çŸ¥è­˜ãªã— ç”»åƒå…¥åŠ›ã®ã¿ã§ */ã‚ã‚‰ã‚†ã‚‹ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°å•é¡Œ/* ã‚’è§£ã‘ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ 

*/äº‹å‰çŸ¥è­˜ãªã—/* : */ç”»åƒãƒ™ãƒ¼ã‚¹ã®ãƒ‰ãƒ¡ã‚¤ãƒ³éä¾å­˜ãƒ—ãƒ©ãƒ³ãƒŠ/*

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
Tower of Hanoi

[[sjpg:hanoi]]
#+end_span6
#+begin_span4
Lights-Out

[[sjpg:lightsout]]
#+end_span4
#+end_row-fluid
#+end_container-fluid

** ã‚·ã‚¹ãƒ†ãƒ ã®å…¥åŠ›

#+begin_xlarge
ï¼’ã¤ã®å…¥åŠ›:

+ Training å…¥åŠ›
+ Planning å…¥åŠ›
#+end_xlarge

** å…¥åŠ›1: Training å…¥åŠ› -- ç”»åƒãƒšã‚¢ã®é›†åˆ

[[png:overview/1]]

** å…¥åŠ›1: Training å…¥åŠ› -- ç”»åƒãƒšã‚¢ã®é›†åˆ

#+begin_right
[[png:overview/2]]
#+end_right

ç’°å¢ƒã‹ã‚‰ *ãƒ©ãƒ³ãƒ€ãƒ ã«* ç”Ÿæˆã—ãŸé·ç§»

+ *å ±é…¬ãªã—* / *ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆçŸ¥è­˜ãªã—*
+ *ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãªã—* (Deep RLã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ã‚’å¸¸ã«ä½¿ã†)
+ 
  #+begin_larger
  */ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ©ãƒ™ãƒ«ãªã—/*

  â†’ ã‚ã‚‹ç”»åƒã®é·ç§»ã§ã€Œä½•ãŒèµ·ãã¦ã„ã‚‹ã‹ã€ã®èª¬æ˜ãŒã¾ã£ãŸãä¸ãˆã‚‰ã‚Œãªã„
  #+end_larger

** å…¥åŠ›2: Planning å…¥åŠ› -- åˆæœŸç”»åƒ & ã‚´ãƒ¼ãƒ«ç”»åƒ

[[png:overview/input2]]

** äº‹å‰çŸ¥è­˜ãªã— ç”»åƒå…¥åŠ›ã®ã¿ã§ */ã‚ã‚‰ã‚†ã‚‹ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°å•é¡Œ/* ã‚’è§£ã‘ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ 

#+HTML: <embed src="img/overview/3.svg" type="image/svg+xml"  />

** äº‹å‰çŸ¥è­˜ãªã— ç”»åƒå…¥åŠ›ã®ã¿ã§ */ã‚ã‚‰ã‚†ã‚‹ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°å•é¡Œ/* ã‚’è§£ã‘ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ 

#+HTML: <embed src="img/overview/3-hanoi.svg" type="image/svg+xml"  />

* Overview

#+begin_center
#+begin_xlarge
*Backgrounds*

*/Latplan Architecture/*

*State AutoEncoder (SAE)*
#+end_xlarge

break

#+begin_xlarge
*AMA_2 Overview*

*Action AutoEncoder (AAE)*

*Action Discriminator (AD)*
#+end_xlarge
#+end_center

* Latent-Space Planner (*/LatPlan/*) architechture

 [[png:overview/planning1]]

** Step 1: å‘½é¡Œå¤‰æ•°ã‚·ãƒ³ãƒœãƒ«ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°

 [[png:overview/planning2]]

*** Step 1: State Autoencoder                                      :noexport:

[[png:train-state-ae]]

Trained SAE provides two functions:

+ $b = Encode(r)$ *maps a raw datum $r\;$ to a bit vector $b\;$*

+ $\tilde{r} = Decode(b)$ *maps a bit vector $b\;$ to a raw datum $\tilde{r}$*

** Step 2: ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã®ç²å¾— (AMA)

 [[png:overview/planning3]]

** Step 3: è¨˜å·çš„ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°å•é¡Œã‚’è¨˜å·çš„ã‚½ãƒ«ãƒã§è§£ã

  [[png:overview/planning4]]

** Step 4: è¨˜å·çš„ãƒ—ãƒ©ãƒ³ã‚’å®Ÿè¡Œã—è¨˜å·çš„çŠ¶æ…‹åˆ—ã‚’å¾—ã‚‹

  [[png:overview/planning5]]

** Step 5: è¨˜å·çš„çŠ¶æ…‹åˆ—ã‚’ç¾å®Ÿã®å†™çœŸã«å¤‰æ›ã™ã‚‹

  [[png:overview/planning6]]

#+begin_center
#+begin_larger
#+end_larger
#+end_center

** ã¾ã¨ã‚

#+begin_xlarge
Latplan: éš ã‚Œç©ºé–“ãƒ—ãƒ©ãƒ³ãƒŠ (Latent-space Planner).
#+end_xlarge

#+begin_larger
+ */ç¾å®Ÿã®è¡¨ç¾/ ã¨ /å‘½é¡Œè«–ç†è¡¨ç¾/ ã‚’æ•™å¸«ç„¡ã—ã§ç›¸äº’å¤‰æ›.*
+ */å‘½é¡Œè«–ç†ã‚’ç”¨ã„ã¦æ­£ã—ã„æ¨è«–ã‚’è¡Œã†/.*
+ */ç¾å®Ÿã®è¡¨ç¾ã§ç­”ãˆã‚’å‡ºåŠ›ã™ã‚‹/* (ç”»åƒãªã©).
+ */æ•™å¸«ç„¡ã—ã§å®Œå…¨è‡ªå‹•ã§å‹•ä½œã™ã‚‹/.*
#+end_larger

* Overview

#+begin_center
#+begin_xlarge
*Backgrounds*

*Latplan Architecture*

*/State AutoEncoder (SAE)/*
#+end_xlarge

break

#+begin_xlarge
*AMA_2 Overview*

*Action AutoEncoder (AAE)*

*Action Discriminator (AD)*
#+end_xlarge
#+end_center

* State AutoEncoder (SAE)

SAE ã¯ãµãŸã¤ã®é–¢æ•°ã‚’å«ã‚€ *ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ*:

+ $b = Encode(r)$ : *ç”Ÿãƒ‡ãƒ¼ã‚¿ $r\;$ ã‚’ãƒ“ãƒƒãƒˆãƒ™ã‚¯ã‚¿ $b\;$ ã«å¤‰æ›*

+ $\tilde{r} = Decode(b)$ : *ãƒ“ãƒƒãƒˆãƒ™ã‚¯ã‚¿ $b\;$ ã‚’ç”Ÿãƒ‡ãƒ¼ã‚¿ $\tilde{r}$ ã«é€†å¤‰æ›*

#+begin_larger
+ *ã‚µãƒ–ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯è¡¨ç¾ã¨ã‚·ãƒ³ãƒœãƒªãƒƒã‚¯è¡¨ç¾ã®åŒæ–¹å‘ãƒãƒƒãƒ”ãƒ³ã‚°*

  #+begin_alignright
   (ãƒ“ãƒƒãƒˆãƒ™ã‚¯ã‚¿ = å‘½é¡Œå¤‰æ•°ã¨åŒå€¤)
  #+end_alignright
#+end_larger

** Neural Network 101                                              :noexport:

[[png:deeplearning/1]]

** Neural Network 101                                              :noexport:

[[png:deeplearning/2]]

** Neural Network 101                                              :noexport:

[[png:deeplearning/3]]

** Stochastic Gradient Descent + GPU                               :noexport:

[[spng:gradient-descent]]

Plus misc techniques e.g. *Batchnorm*, *Dropout*

#+begin_larger
*Pretty much everything is on the standard online tutorial / lecture cource / MOOP*

*Good libraries --- Tensorflow, Keras* --- you can learn in 1-2 months
#+end_larger

** ã€Œãµã¤ã†ã®ã€åˆ†é¡ã‚¿ã‚¹ã‚¯ç”¨ã®NN (æ•™å¸«ã‚ã‚Š)

# Target Function $y=f(x)\;$ trained by SGD minimizing $|y-f(x)|$
# 
# #+begin_alignright
# SGD: Stochastic Gradient Descent
# #+end_alignright
  
| Task           | Input x | Output y                     |
|----------------+---------+------------------------------|
| ç”»åƒã‚¯ãƒ©ã‚¹åˆ†ã‘ | ç”»åƒ    | ãƒ©ãƒ™ãƒ« (1=ğŸš—, 2=ğŸ˜º, 3=ğŸµ ...) |
# | Translation          | Sentence | Sentence                           |
# | Go eval. function    | State    | Number                             |

#+begin_larger
 + *ã“ã‚Œã§ã¯Latplanã«ã¯ä½¿ãˆãªã„*
   + *Latplanå…¥åŠ›ã«äººã®ä¸ãˆãŸ /ãƒ©ãƒ™ãƒ«ã¯ãªã„/* ã€ã¤ã¾ã‚Š
   + ã‚·ãƒ³ãƒœãƒ«ã‚’ */ã©ã†ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹ã‹/* ã¯æ©Ÿæ¢°ã®æ°—åˆ†æ¬¡ç¬¬
     
     ã€€

     #+begin_alignright
     (*å®Ÿéš›ã€äººé–“ã‚‚ã€åŒã˜ã‚‚ã®ã‚’åˆ¥ã®å½¢ã§è¨˜å·æ¥åœ°ã—ã†ã‚‹ã€‚*
     
     cf. è™¹ğŸŒˆ ã¯ä½•è‰²ã§å‡ºæ¥ã¦ã„ã‚‹?)
     #+end_alignright

#+end_larger

** ã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€(AE)ã‚’ä½¿ã£ãŸæ•™å¸«ãªã—å­¦ç¿’

# Auto = "self" --- Autoencoding = "encoding itself"

#+begin_container-fluid
#+begin_row-fluid
#+begin_span7
ã€€

ç›®æ¨™é–¢æ•°: Identity $x=f(x)$
+ $x\;$ ã‚’ *éš ã‚Œè¡¨ç¾* $z$ ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
+ $z\;$ ã‚’ å…¥åŠ› $x$ ã«ãƒ‡ã‚³ãƒ¼ãƒ‰
+ $z\;$ ã¯å°ã•ãªæ¬¡å…ƒæ•°: æ¬¡å…ƒåœ§ç¸®
+ è¨“ç·´: $|x - f(x)|\;$ ã‚’æœ€å°åŒ–
  (*è‡ªå·±ç¬¦å·åŒ–ãƒ­ã‚¹*)
#+end_span7
#+begin_span5
[[png:deeplearning/autoenc]]
#+end_span5
#+end_row-fluid
#+end_container-fluid

#+begin_alignright
#+begin_larger
+ â†’ ã—ã‹ã—, */âœ˜ éš ã‚Œãƒ™ã‚¯ã‚¿ Z ã¯å®Ÿæ•°å€¤/*

  */å‘½é¡Œè«–ç†ã«ã‚ˆã‚‹æ¨è«–ã«ã¯ä½¿ãˆãªã„/*
#+end_larger
#+end_alignright

** Variational AutoEncoder (VAE)                                   :noexport:

An AutoEncoder that *enforce a certain distribution* on $Z \subset \mathbb{R}^n$ over the dataset $X$

#+begin_quote
You have $X=$ { 10k images of apples }. If you train a *Gaussian VAE* on $X$, then $Z = Encode(X) \approx N(\mu,\sigma)$ for some $\mu,\sigma \in \mathbb{R}^n$.
#+end_quote

VAE needs a *reparametrization trick* because random distributions are non-differentiable.

#+begin_quote
Reparametrization for $N(\mu,\sigma)$: $\mu + \sigma N(0,1)$

#+begin_center
\mu and \sigma are differentiable vectors, $N(0,1)$ is not.
#+end_center
#+end_quote

** Gumbel-Softmax VAE (Jang, Gu, ICLR2017)

*AEã«ã‚³ã‚¹ãƒˆé–¢æ•°ã‚’è¿½åŠ * ã—ã€ $Z \sim \textbf{Categorical}$ ã«åæŸã™ã‚‹ã‚ˆã†å¼·åˆ¶:

ã€€ã€€ã€€â†’ $z\;$ ã¯ 1-hot ãƒ™ã‚¯ã‚¿ã«åæŸ e.g.  $\langle 0,0,1,0 \rangle$ .

ä¾‹: MNIST ç”»åƒã‚’ 8ã‚«ãƒ†ã‚´ãƒªå¤‰æ•° 30å€‹ã§è¡¨ç¾

#+begin_center
 #+begin_html
 <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="649px" height="206px" version="1.1" content="&lt;mxfile userAgent=&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36&quot; version=&quot;6.0.1.2&quot; editor=&quot;www.draw.io&quot; type=&quot;google&quot;&gt;&lt;diagram name=&quot;Page-1&quot;&gt;3ZhLc5swEMc/Dcd0kAQCX+O67SGd6TTTaXqU0fJoZcsjy69++oogDBjs0MZ2TONDpL9ey29Xi5BDxrPtR8UW6WfJQTjY5VuHvHcwxshF5l+u7AqF+rgQEpXxQkKV8Jj9Biu6Vl1lHJaNjlpKobNFU4zkfA6RbmhMKblpdoulaK66YAm0hMeIibb6PeM6LdTQdyv9E2RJWq6MXNsyY2VnKyxTxuWmJpGJQ8ZKSl2UZtsxiBxeyaUY9+FI694wBXPdZ0AQh1EYx4xP46kXRHBnZ1gzsbIPaw3Vu/LpN2mm4XHBory+MR52yH2qZ8LUkCnGmRBjKaR67k0AcR8Coy+1kr+g1jKiAWHUtCi5mnPgdrw1AJSG7dGnQntWJshAzkCrneliB5CAFENsfCHPL+qbylt7n6Q1T+HAisxGSLKfu4JoCpZjT6a4xRT71MFUmFXvebY2xSQvfoWHb6VsFqm1tHygUjmbroyR9y944ww08QFN7LktmmEHzPASLEmLpY/wcFiiW2LptVAAN3nOVqXSqUzknIlJpdb2qtuEA9tMP9XKP/Iu7/y8NjeGPtkRz5Wq7SdovbMJnq20NFK17oOUiwb63LzT4M3TyJWK4HT0aKYS0Kd2a9uBCgTT2bq5/mvc4eEIU4xG4PsesCDqCO1z+ufKpBHugZq8FeorRf6VmfdBfiQ9XR45HXbi9kf4zRJ3i2Uw7AOFd0ssw//9JXgseupponu3Ht8MwYEDL+KZ0cDehyeBBqd3BB31B2pn+SIzY0D/KYqYsKMO3LK36N88hc7+1cgZhHHU9dVIoxCm8SW+GukINQm67bSEaEde2otnDX901nAfRGaiPTYSutYJ5uiRdthRfldeot1IlPfI8i9Abcb8AeLYz3+diJ//Xgm1hIg6IHpdEL1LQCxvEwcK0Q4I3IP8+8ZQX/9SuwGoJGxud+STFtSQtpli3/trpqZa3VwX54rq/p9M/gA=&lt;/diagram&gt;&lt;/mxfile&gt;"><defs/><g transform="translate(0.5,0.5)"><rect x="288" y="0.75" width="75" height="202.5" rx="11.25" ry="11.25" fill="#e1d5e7" stroke="#9673a6" pointer-events="none"/><path d="M 243 72 L 273 102 L 243 132 L 213 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(231.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">256<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 168 72 L 198 102 L 168 132 L 138 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(156.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">512<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 198 102 L 208.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 212.16 102 L 206.91 104.63 L 208.22 102 L 206.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 120.75 102 L 135.75 102 L 123 102 L 133.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 137.16 102 L 131.91 104.63 L 133.22 102 L 131.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 273 102 L 288 102 L 273 102 L 283.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 287.16 102 L 281.91 104.63 L 283.22 102 L 281.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 482.25 72 L 512.25 102 L 482.25 132 L 452.25 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(470.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">512<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 407.25 72 L 437.25 102 L 407.25 132 L 377.25 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(395.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">256<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 437.25 102 L 447.47 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 451.41 102 L 446.16 104.63 L 447.47 102 L 446.16 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 360 102 L 375 102 L 362.25 102 L 372.47 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 376.41 102 L 371.16 104.63 L 372.47 102 L 371.16 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><rect x="526.5" y="42" width="120" height="120" rx="18" ry="18" fill="#dae8fc" stroke="#6c8ebf" pointer-events="none"/><path d="M 512.25 102 L 521.72 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 525.66 102 L 520.41 104.63 L 521.72 102 L 520.41 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><rect x="0.75" y="42" width="120" height="120" rx="18" ry="18" fill="#dae8fc" stroke="#6c8ebf" pointer-events="none"/>
 <image xlink:href="img/static/x0.gif" x="8.25" y="49.5" width="105" height="105" fill="#f5f5f5" stroke="#666666" pointer-events="none"/>
 <image xlink:href="img/static/x1.gif" x="534" y="49.5" width="105" height="105" fill="#f5f5f5" stroke="#666666" pointer-events="none"/>
 <image xlink:href="img/static/y.gif" x="293.25" y="6.75" width="64.5" height="190.5" fill="#f5f5f5" stroke="#666666" pointer-events="none"/></g></svg>
 #+end_html
#+end_center

#+begin_center
+ éµã¨ãªã‚‹ã‚¢ã‚¤ãƒ‡ã‚£ã‚¢: *ã“ã‚Œã‚‰ã®ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã¯ /ç›´æ¥/*

  *å‘½é¡Œè«–ç†çš„ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦æ‰±ãˆã‚‹*

  ç‰¹ã«, *ã‚«ãƒ†ã‚´ãƒªæ•° = 2 â†’ æ´»æ€§åŒ–å€¤ãŒå‘½é¡Œå¤‰æ•°ã®å€¤ã«ç›¸å½“ (0/1 = çœŸ/å½)*
#+end_center

** State Autoencoder (*/è¨“ç·´å‰/*)

 [[png:sae/state-ae-before]]

** State Autoencoder (_/è¨“ç·´å¾Œ/_)

 [[png:sae/state-ae]]

** Gumbel-Softmax: Differential Approximation of Gumbel-Max        :noexport:

#+begin_larger
It uses *annealing* to approximate discrete vectors
#+end_larger

#+begin_smaller
Gumbel-Max: Method for drawing one-hot vector sample ($z$) from category probability ($x$)

+ E.g.: $x=[0.1, 0.1, 0.8] \rightarrow z = [1,0,0] \text{or} [0,1,0] \text{or} [0,0,1]$

+ $z = \text{ GumbelMax}(x) = [ i == \arg \max_j (\text{ Gumbel}(0,1)+\log x_j) \; ? \; 1 : 0 ]$

+ argmax is non-differentiable â†’ softmax approximation (differentiable)

+ $z = \text{ GumbelSoftmax}_\tau (x) = \text{ Softmax}( [\text{ Gumbel}(0,1)+\log x_j]/\tau )$

+ Temparature $\tau \rightarrow 0$ , $z\rightarrow \text{one-hot vector}$

  # \[
  # \text{ GumbelSoftmax}_\tau (x) \rightarrow \text{ GumbelMax}(x) \quad (\tau\rightarrow 0)
  # \]
#+end_smaller

#+begin_container-fluid
#+begin_row-fluid
#+begin_span2

#+end_span2
#+begin_span8
#+begin_center
[[png:sae/gumbel]]
#+end_center
#+end_span8
#+begin_span2

#+end_span2
#+end_row-fluid
#+end_container-fluid

#+begin_note
Maddison et. al., 2014
#+end_note

* å®Ÿé¨“: State Autoencoder (SAE) ã®ä½œã£ãŸå‘½é¡Œå¤‰æ•°ã§ã€Œè«–ç†çš„ã«æ­£ã—ãæ¨è«–ã§ãã‚‹ã‹?ã€

å…¨ã¦ã®çŠ¶æ…‹é·ç§»ã‚’ç”Ÿæˆã—ã¦ã€ãã‚Œãã‚Œã‚’PDDLã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«ç¿»è¨³ã€æ±ç”¨ã‚½ãƒ«ãƒã‚’ç”¨ã„ã¦è§£ã

(ã¤ã¾ã‚Šã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ç²å¾—ã¯çœç•¥)

#+begin_src lisp
 0011 â†’ 0101  

ã€€ã€€ã€€â†“       ;; çŠ¶æ…‹é·ç§»ã”ã¨ã«ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ï¼‘ã¤ä½œè£½
(:action       action-0011-0101
               ;; å‰ææ¡ä»¶ã¯é·ç§»å‰ã®çŠ¶æ…‹ã‚’ãã®ã¾ã¾ä½¿ã†
 :precondition (and (b0-false) (b1-false) (b2-true) (b3-true))
               ;; åŠ¹æœ = çŠ¶æ…‹ã®å·®åˆ†
 :effect       (and (not (b1-false)) (b1-true)
                    (not (b2-true))  (b2-false)))
#+end_src

ãã‚Œãã‚Œã®ãƒ“ãƒƒãƒˆã‚’å‘½é¡Œã«å¤‰æ›

#+begin_center
 $i$-th bit ãŒ 1 â†’ å‘½é¡Œ ($b_i$ -true)

 $i$-th bit ãŒ 0 â†’ å‘½é¡Œ ($b_i$ -false)
#+end_center

*** Example PDDL

# Examples in $N=25$ (in the paper we bypassed PDDL-SAS translater)

#+begin_src lisp
(define (domain latent)
 (:requirements :strips)
 (:predicates (b0-true) (b0-false) (b1-true) ... (b24-false))

 (:action a10000010010110111100011111000010001011111110011111
  :parameters () :precondition
  (and (b0-true) (b1-false) (b2-false) ... (b24-true))
  :effect (and (not (b5-false))  (b5-true)
               (not (b6-true))   (b6-false)
               (not (b13-false)) (b13-true)
               (not (b20-false)) (b20-true)))

 (:action a10000010010110111100011110000001001011011110001110
  ...
#+end_src

** Step 3: ã“ã®PDDLã‚’ä½¿ã£ã¦å•é¡Œã‚’è§£ã

  [[png:overview/planning4]]

** Step 4: ãƒ—ãƒ©ãƒ³ã‚’å®Ÿè¡Œã—

  [[png:overview/planning5]]

** Step 5: çµæœã‚’å¯è¦–åŒ–

  [[png:overview/planning6]]

# * AMA_1 Experiments
# 
# SAE: *trained with 20k images* (note: > 360k entire states in 8-puzzle)
# 
# + */SAE is generalizing/*
# 
# AMA_1: requires the entire transistions (note: > 1M transitions in 8-puzzle)
# 
# + _/AMA_1 is NOT generalizing, being an oracle/_
# 
# Planner: a State-of-the-Art, Fast Downward (Helmert, 08)
# 
# + $A^*$ *(optimal search)* : *It must find an optimal solution*
# 
# + Runtime: ~3sec (instances are too small for symbolic systems)

** 8-puzzle Results with MNIST tiles (MNIST 8-puzzle)

 [[png:results/mnist-plan]]

 #+begin_larger
 #+begin_xlarge
 #+begin_alignright
  â†’ *31æ‰‹ã®æœ€é©è§£ã‚’è¿”å´*
 #+end_alignright
 #+end_xlarge
 #+end_larger

** å†™çœŸãƒ™ãƒ¼ã‚¹ã®8ãƒ‘ã‚ºãƒ«: ã‚¿ã‚¤ãƒ«ãŒæ˜ç¢ºã«åˆ†é›¢ã•ã‚Œã¦ã„ãªã„ (Mandrill 8ãƒ‘ã‚ºãƒ«)

MNIST 8ãƒ‘ã‚ºãƒ«ã¯ ã‚¿ã‚¤ãƒ«åŒå£«ãŒãã£ãã‚Šåˆ†é›¢ã—ã¦ã„ãŸ -> å¢ƒç•ŒãŒã‚ˆãåˆ†ã‹ã‚‰ãªãã¦ã‚‚å¤§ä¸ˆå¤«ã‹?

[[png:results/mandrill-intro]]

** å†™çœŸãƒ™ãƒ¼ã‚¹ã®8ãƒ‘ã‚ºãƒ«: ã‚¿ã‚¤ãƒ«ãŒæ˜ç¢ºã«åˆ†é›¢ã•ã‚Œã¦ã„ãªã„ (Mandrill 8ãƒ‘ã‚ºãƒ«)

[[png:results/mandrill-plan]]

#+begin_xlarge
#+begin_alignright
 â†’ *æœ€é©è§£*
#+end_alignright
#+end_xlarge

** å†™çœŸãƒ™ãƒ¼ã‚¹ã®8ãƒ‘ã‚ºãƒ«: ã‚¿ã‚¤ãƒ«ãŒæ˜ç¢ºã«åˆ†é›¢ã•ã‚Œã¦ã„ãªã„ (Spider 8ãƒ‘ã‚ºãƒ«)

[[png:results/spider-plan-new]]

#+begin_center
#+begin_larger
*Latplan ã¯ ã“ã®å•é¡ŒãŒ8ãƒ‘ã‚ºãƒ«ã¨å‘¼ã°ã‚Œã¦ã„ã‚‹ã“ã¨ã™ã‚‰çŸ¥ã‚‰ãªã„ã“ã¨ã«æ³¨æ„*; MNIST, Mandrill, Spider ã¯ æ©Ÿæ¢°ã«ã¨ã£ã¦ã¯å…¨ã¦ç•°ãªã‚‹ãƒ‰ãƒ¡ã‚¤ãƒ³
#+end_larger
#+end_center

** ãƒãƒã‚¤ã®å¡” (3 disks, 4 disks)

å…¨ãåˆ¥ç¨®ã®ãƒ‘ã‚ºãƒ«ã§ã‚‚åŒã˜ã‚·ã‚¹ãƒ†ãƒ ã§è§£ãã“ã¨ãŒå‡ºæ¥ã‚‹

[[png:results/hanoi3]]

[[png:results/hanoi4]]

#+begin_alignright
#+begin_xlarge
 â†’ *æœ€é©è§£* (7 steps,15 steps)
#+end_xlarge
#+end_alignright

** ãƒ©ã‚¤ãƒ„ã‚¢ã‚¦ãƒˆ

å…¨ãåˆ¥ç¨®ã®ãƒ‘ã‚ºãƒ«ã§ã‚‚åŒã˜ã‚·ã‚¹ãƒ†ãƒ ã§è§£ãã“ã¨ãŒå‡ºæ¥ã‚‹

[[png:results/lightsout_new4x4]]

#+begin_alignright
#+begin_xlarge
 â†’ *æœ€é©è§£*
#+end_xlarge
#+end_alignright

** Twisted Lights Out

å…¥åŠ›ç”»åƒã«æ­ªã¿ã‚’åŠ ãˆã¦ã€Œæ ¼å­çŠ¶ã€ã¨ã„ã†åˆ¶é™ã‚’ãªãã™

[[png:results/lightsout_twisted_new4x4]]

#+begin_alignright
#+begin_xlarge
 â†’ *æœ€é©è§£*
#+end_xlarge
#+end_alignright

** ãƒã‚¤ã‚ºè€æ€§

SAE ã®å®Ÿè£…ã« Denoising AE ã‚’ç”¨ã„ã¦ã„ã‚‹ãŸã‚ã€ãƒã‚¤ã‚ºã«æƒ‘ã‚ã•ã‚Œãšå‘½é¡Œã«ãƒãƒƒãƒ—ã§ãã‚‹

[[png:results/noise-new]]

#+begin_larger
#+begin_alignright
 â†’ *æ—¢å­˜ã®ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°æŠ€è¡“ã‚’ã™ãæ´»ç”¨ã§ãã‚‹*

 â†’ *é€Ÿã„è¨“ç·´ã€é ‘å¥æ€§ã€ç²¾åº¦*
#+end_alignright
#+end_larger
* Why bother the off-the-shelf planner? Shouldn't the blind search do? :noexport:

*Domain-independent lowerbounds works, /SURPRISINGLY!/*

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
+ This is *NOT* a trivial finding!

  lower-bounds are...

  + taylored for *man-made* domains
  
  + assumes the domain has a *structure*

  Blind search even sometimes outperform sophisticated methods on man-made instances (Edelkamp 12)

+ lb works â†’ *the more difficult problems can be solved (future work)*
#+end_span6
#+begin_span6
#+begin_smaller

| domain          | Dijkstra   | A*+PDB          | instances |
|-----------------+------------+-----------------+-----------|
| MNIST           | 210k(50k)  | *97k* (53k)     |        13 |
| Mandrill        | 176k(13k)  | *112k* (57k)    |        12 |
| Spider          | 275k(65k)  | *58k* (30k)     |        13 |
| Hanoi (4 disk)  | 20.7(29.7) | *12.6* (22.0)   |        30 |
| LightsOut (4x4) | 433(610.4) | *130.3* (164.4) |        16 |
| Twisted   (4x4) | 398(683.1) | *29.3* (62.4)   |        16 |
|-----------------+------------+-----------------+-----------|

#+end_smaller
#+end_span6
#+end_row-fluid
#+end_container-fluid

* Why Gumbel-Softmax is necessary?                                 :noexport:

+ Alternative 1: Use a normal NN and *round* the encoder output?
  + âœ˜ The *decoder* is not trained with 0/1 value
+ Alternative 2: Include the *round* operation in a NN?
  + âœ˜ Rounding is *non-differentiable* / *Backpropagation impossible*

* State Autoencoder å®Ÿé¨“ã¾ã¨ã‚

+ SAE ã¯å°ã•ãªå…¥åŠ›ã‹ã‚‰å­¦ç¿’ã§ãã‚‹ ::

     è¨“ç·´ç”»åƒ 20kæš â†’ è¦‹ãŸã“ã¨ã®ãªã„ 360k æšã®ç”»åƒã‚’æ­£ã—ãå¾©å…ƒã§ãã‚‹

+ SAEã®ç”Ÿæˆã—ãŸå‘½é¡Œå¤‰æ•°ã¯å¥å…¨ã§ã‚ã‚‹ ::

     ãã‚Œã‚’ç”¨ã„ã¦è¨˜å·çš„ãƒ—ãƒ©ãƒ³ãƒŠãŒæ¨è«–ã‚’è¡Œãˆã‚‹

+ Latplan ã¯æ ¸ã¨ãªã‚‹è¨˜å·çš„ãƒ—ãƒ©ãƒ³ãƒŠã®ç†è«–çš„æ€§è³ªã‚’å—ã‘ç¶™ã ::

  æœ€é©ã‚³ã‚¹ãƒˆè§£ã‚’ä¿è¨¼ã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  (A*ç­‰) ã‚’ä½¿ãˆã°ã€ç”»åƒã«ã‚ˆã‚‹çµæœã‚‚æœ€é©è§£

  å®Œå…¨æ€§ã®ã‚ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’ä½¿ãˆã°ã€è§£ãŒå­˜åœ¨ã™ã‚‹å ´åˆã«ã¯å¿…ãšç™ºè¦‹ã™ã‚‹

* *** â˜• Break â˜• ***

#+begin_center
#+begin_xlarge
*Backgrounds*

*Latplan Architecture*

*State AutoEncoder (SAE)*
#+end_xlarge

*/â˜• Break â˜•/*

#+begin_xlarge
*AMA_2 Overview*

*Action AutoEncoder (AAE)*

*Action Discriminator (AD)*
#+end_xlarge
#+end_center

* Overview

#+begin_center
#+begin_xlarge
*Backgrounds*

*Latplan Architecture*

*State AutoEncoder (SAE)*
#+end_xlarge

break

#+begin_xlarge
*/AMA_2 Overview/*

*Action AutoEncoder (AAE)*

*Action Discriminator (AD)*
#+end_xlarge
#+end_center

* SAE Feasible! Now what?

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
*å…ˆç¨‹ã®å®Ÿé¨“ã§ã¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ç²å¾—(AMA)ã‚’ã‚¹ã‚­ãƒƒãƒ—ã€å¤–éƒ¨ã‹ã‚‰ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ã‚’ä¸ãˆãŸ*

SAEã¯ *ç¾å®Ÿã®çŠ¶æ…‹ã‚’å‘½é¡Œè¡¨ç¾ã«ã™ã‚‹ã ã‘* ãªã®ã§ã€ *ä¸–ç•ŒãŒã©ã†å¤‰åŒ–ã™ã‚‹ã‹ã¯çŸ¥ã‚‰ãªã„*

# #+begin_center
# + *AMA ã¯ã€å°‘æ•°ã®çŠ¶æ…‹é·ç§»ã®ä¾‹ã‹ã‚‰ä¸–ç•Œã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ã‚’ä½œã‚‹*
# #+end_center
#+end_span6
#+begin_span6
 [[png:overview/ama1]]
#+end_span6
#+end_row-fluid
#+end_container-fluid

#+begin_larger
#+begin_alignright
+ â†’ æ–°ãŸãªãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆ *AMA_2* ã§AMAã‚’å®Ÿè¡Œ
#+end_alignright
#+end_larger

* AMA_2 : */æœ¬ç‰©ã®/* AMA method

*å…¥åŠ›:* çŠ¶æ…‹é·ç§» $\{ (s,t) \ldots \}$

#+begin_alignright
(SAEã§å‘½é¡Œè«–ç†è¡¨ç¾ã«å¤‰æ›æ¸ˆã¿)
#+end_alignright

+ *ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚·ãƒ³ãƒœãƒ«ãƒ»ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°*
  
  #+begin_src lisp
  (:action slide-up-tile7-at-x0-y1 ...
  #+end_src
+ *å‰ææ¡ä»¶ã®å­¦ç¿’*
  
  #+begin_src lisp
   :precondition (and (empty x0 y0) ...)
  #+end_src
+ *åŠ¹æœã®å­¦ç¿’*
  
  #+begin_src lisp
   :effects      (and (empty x0 y1) (not ...)))
  #+end_src

** Action Symbol Grounding                                         :noexport:

Identifing a *type* of transition (clustering)

#+begin_container-fluid
#+begin_row-fluid
#+begin_span9
#+begin_src lisp
(:action slide-up-tile7-at-x0-y1 ...
 :precondition ...
 :effects      ...)
 #+end_src
 #+end_span9
#+begin_span3
initial state
[[png:8puzzle-standard-tile7]]
#+end_span3
#+end_row-fluid
#+end_container-fluid

# + E.g. *slide-up-tile7-at-x0-y1* action abstracts all transitions that looks like this
# 
# + â†’ not merely an individual transition

** Action Precondition Learning                                    :noexport:

Learns *when* that transition is allowed

#+begin_container-fluid
#+begin_row-fluid
#+begin_span9
#+begin_src lisp
(:action slide-up-tile7-at-x0-y1 ...
 :precondition (and (empty x0 y0) ...)
 :effects      ...)
#+end_src
#+end_span9
#+begin_span3
initial state
[[png:8puzzle-standard-tile7]]
#+end_span3
#+end_row-fluid
#+end_container-fluid

** Action Effect Learning                                          :noexport:

Learns *what* happens after the transition

#+begin_container-fluid
#+begin_row-fluid
#+begin_span9
#+begin_src lisp
(:action slide-up-tile7-at-x0-y1 ...
 :precondition (and (empty x0 y0) ...)
 :effects      (and (empty x0 y1) (not ...)))
#+end_src
#+end_span9
#+begin_span3
initial state
[[png:8puzzle-standard-tile7]]
#+end_span3
#+end_row-fluid
#+end_container-fluid

#+begin_alignright
+ AMA_2 perform all three processes.
#+end_alignright

** ãªãœ */ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚·ãƒ³ãƒœãƒ«/* ãŒå¿…è¦ãªã®ã‹?

 å‰ææ¡ä»¶ã¨åŠ¹æœã®å­¦ç¿’ã®å¿…è¦æ€§ã¯è‡ªæ˜ã€ã—ã‹ã—ãªãœã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚·ãƒ³ãƒœãƒ«?

 ãƒ—ãƒ©ãƒ³ãƒŠã¯ ã‚°ãƒ©ãƒ•ä¸Šã® *å‰æ–¹æ¢ç´¢* *(Dijkstra, $A^ï¼Š$ )* ã§å•é¡Œã‚’è§£ãã®ãŒä¸»æµ

 ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚·ãƒ³ãƒœãƒ«ãªã—ã§ã¯ã€ *å¾Œè€…çŠ¶æ…‹ã®ç”Ÿæˆ* ãŒé›£ã—ããªã‚‹

 + $|z|=36 \text{bit}$ ã®SAEã®å ´åˆ:

   â†’ å¯èƒ½æ€§ã®ã‚ã‚‹å¾Œè€…çŠ¶æ…‹ã¯ *$2^{36}$* å€‹ã‚ã‚Šã€ã“ã‚Œã‚’äºŒå€¤åˆ†é¡æ©Ÿãªã©ã§ãµã‚‹ã„ã‚ã‘

 + */ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚·ãƒ³ãƒœãƒ«ãŒã‚ã‚Œã°/ (ä¾‹: ä¸Šä¸‹å·¦å³)*

 + â†’ è€ƒãˆã‚‹ã¹ãå¾Œè€…çŠ¶æ…‹ã®å€™è£œã¯ */å®šæ•°æ™‚é–“/ ã§åˆ—æŒ™ã§ãã‚‹* (ä¾‹: 4ã¤).

** èª²é¡Œ: æ¡ä»¶/åŠ¹æœã®å­¦ç¿’ãŒè‡ªæ˜ã§ãªã„

*Training å…¥åŠ› ã«ã¯ã€ãã®é·ç§»ãŒä½•ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚’è¡¨ã™ãƒ©ãƒ™ãƒ«ãŒã¤ã„ã¦ã„ãªã„*

ãŸã ã®ç”»åƒãƒšã‚¢

[[png:ama/action-symbol]]

+ â†’ *ã©ã®çŠ¶æ…‹é·ç§»ãŒã€ŒåŒã˜ã‚¿ã‚¤ãƒ—ã®é·ç§»ã€=ã€ŒåŒã˜ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€ãªã®ã‹ã‚’çŸ¥ã‚‰ãªã„*

** èª²é¡Œ: æ¡ä»¶/åŠ¹æœã®å­¦ç¿’ãŒè‡ªæ˜ã§ãªã„

#+begin_xlarge
Case 1: ç·šå½¢ãªæ¢ç´¢ç©ºé–“
#+end_xlarge

+ *ç·šå½¢ãªç©ºé–“ã§ã¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒ©ãƒ™ãƒ«ã¯å¿…è¦ãªã„*; ã©ã†ã›ä¸€ç›´ç·šã€åˆ†å²ãªã—
+ ã“ã®å ´åˆ AMA â‰¡ *äºˆæ¸¬ã‚¿ã‚¹ã‚¯* ($\approx$ ãƒ“ãƒ‡ã‚ªã®æ¬¡ãƒ•ãƒ¬ãƒ¼ãƒ ã®äºˆæ¸¬)
  + çŠ¶æ…‹é·ç§»é–¢æ•° $a(s) = t\;$ ã‚’è¿‘ä¼¼ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã‚’ã€èª¤å·® $|t-a(s)|$ ã‚’æœ€å°åŒ–ã—ã¦è¨“ç·´ã™ã‚Œã°ã„ã„ã€‚
  + ç¾çŠ¶ã®ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ç•Œã®AMAã¯å…¨ã¦ã“ã‚Œ

[[png:ama/linear]]

** èª²é¡Œ: æ¡ä»¶/åŠ¹æœã®å­¦ç¿’ãŒè‡ªæ˜ã§ãªã„

#+begin_xlarge
Case 2: å®Ÿéš›ã¯ */ã‚°ãƒ©ãƒ•/*
#+end_xlarge

#+begin_container-fluid
#+begin_row-fluid
#+begin_span7
#+begin_center
+ *è¤‡æ•°ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚·ãƒ³ãƒœãƒ«*
+ *ãƒãƒ¼ãƒ‰ã«ã‚ˆã£ã¦ /å­ä¾›ã®æ•°ãŒç•°ãªã‚‹/*

+ *ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ $a$ ã”ã¨ã« $a(s) = t\;$ ã‚’è¨“ç·´ã™ã‚‹ã“ã¨ã¯ã§ããªã„* ã€
  ãªãœãªã‚‰ *ä¸ãˆã‚‰ã‚ŒãŸ (s,t) ãŒã©ã® $a$ ã«å±ã™ã‚‹ã®ã‹æœªçŸ¥.*
#+end_center

#+end_span7
#+begin_span5
[[png:ama/non-linear]]
#+end_span5
#+end_row-fluid
#+end_container-fluid

#+begin_alignright
#+begin_larger
+ *ã“ã“ã§å•ã‚ã‚Œã‚‹ã¹ãæ­£ã—ã„è³ªå•*: AMAã®ãŸã‚ã« *å­¦ç¿’ã™ã‚‹ã¹ãé–¢æ•°ã¯ä½•ãªã®ã‹?*
#+end_larger
#+end_alignright

* AMA_2 Overview

[[png:ama/overview0]]

** AMA_2 Overview

 [[png:ama/overview1]]

** AMA_2 Overview

 [[png:ama/overview1-1]]

** AMA_2 Overview

 [[png:ama/overview2]]

** AMA_2 Overview

 [[png:ama/overview3]]
* Overview

#+begin_center
#+begin_xlarge
*Backgrounds*

*Latplan Architecture*

*State AutoEncoder (SAE)*
#+end_xlarge

break

#+begin_xlarge
*AMA_2 Overview*
 
*/Action AutoEncoder (AAE)/*

*Action Discriminator (AD)*
#+end_xlarge
#+end_center

* Action AutoEncoder

 AMAã®ãŸã‚ã« *å­¦ç¿’ã™ã‚‹ã¹ãé–¢æ•°ã¯ä½•ãªã®ã‹?*

#+begin_center
#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
+ $a(s) = t$ ? ãƒ€ãƒ¡!
+ $a$ ã¯å®Ÿéš›ã«ã¯ *å¤‰æ•°ã§ã‚ã‚‹*
#+end_span6
#+begin_span6
+ $apply(a,s) = t$
+ çŠ¶æ…‹é·ç§»ã¨ã¯ã€å†™åƒ $a \rightarrow t$ ã‚’

  *$s$ ã§æ¡ä»¶ä»˜ã‘ãŸã‚‚ã®* ã§ã‚ã‚‹
  
+ *å­¦ç¿’ã™ã‚‹ã¹ãé–¢æ•°ã¯ã“ã‚Œã !*
#+end_span6
#+end_row-fluid
#+end_container-fluid
#+end_center
* Action AutoEncoder

[[png:aae/aae-0]]

** Action AutoEncoder

[[png:aae/aae-1]]

** Action AutoEncoder

[[png:aae/aae-2]]

** Action AutoEncoder

[[png:aae/aae-3]]

* Overview

#+begin_center
#+begin_xlarge
*Backgrounds*

*Latplan Architecture*

*State AutoEncoder (SAE)*
#+end_xlarge

break

#+begin_xlarge
*AMA_2 Overview*

*Action AutoEncoder (AAE)*

*/Action Discriminator (AD)/*
#+end_xlarge
#+end_center

* AAE ã¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚·ãƒ³ãƒœãƒ«ã¨åŠ¹æœã ã‘

å‰ææ¡ä»¶ã¯å­¦ç¿’ã—ãªã„

 [[png:ama/overview1-1]]

* Action Discriminator ã¯ äºŒå€¤åˆ†é¡æ©Ÿ

*äºŒå€¤åˆ†é¡æ©Ÿ*, ã©ã®é·ç§»ãŒæ­£ã—ã„ã‹ç­”ãˆã‚‹

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
[[png:aae/ad]]
#+end_span6
#+begin_span6
+ *æ­£ä¾‹* ã¨ *è² ä¾‹* ã‹ã‚‰è¨“ç·´

#+begin_center
+ *æ­£ä¾‹: æ­£ã—ã„çŠ¶æ…‹é·ç§» (è¦³å¯Ÿã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿) ã¯æ‰‹å…ƒã«ã‚ã‚‹.*
+ *è² ä¾‹ ( /è¨±ã•ã‚Œãªã„é·ç§»/ ) ã®ãƒ‡ãƒ¼ã‚¿ã¯ã©ã“ã«ã‚ã‚‹...?*
#+end_center
#+end_span6
#+end_row-fluid
#+end_container-fluid

** è¨±ã•ã‚Œãªã„é·ç§»

+ */è¨±ã•ã‚Œãªã„é·ç§»/*: *è¨±ã•ã‚Œã‚‹é·ç§»ã§ã¯ãªã„å…¨ã¦ã®é·ç§».*
  + ãã‚‚ãã‚‚ã€Œè¨±ã•ã‚Œã‚‹é·ç§»ã€ã‚’çŸ¥ã‚ŠãŸã„ã®ã§æœªçŸ¥ã€å¾“ã£ã¦ *æ©Ÿæ¢°çš„ç”Ÿæˆã¯ä¸å¯èƒ½.*

    ç”ŸæˆãŒä¸å¯èƒ½ãªã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’é›†ã‚ã‚Œã°è‰¯ã„?

#+begin_container-fluid
#+begin_row-fluid
#+begin_span2

#+end_span2
#+begin_span6
[[png:aae/teleportation]]
#+end_span6
#+begin_span2

#+end_span2
#+end_row-fluid
#+end_container-fluid

+ *ç¬é–“ç§»å‹•ã¯ç‰©ç†æ³•å‰‡ã«åã™ã‚‹*. (å°‘ãªãã¨ã‚‚å·¨è¦–çš„ã«ã¯)
  + è‡ªå¾‹è¡Œå‹•AIã«ã¨ã£ã¦

    *è¨±ã•ã‚Œãªã„é·ç§»ã¯ /èµ·ã“ã‚Šå¾—ãªã„/, å¾“ã£ã¦ /è¦³å¯Ÿã•ã‚Œå¾—ãªã„/.*

#+begin_alignright
#+begin_larger
+ è¨±ã•ã‚Œãªã„é·ç§» ã®ãƒ‡ãƒ¼ã‚¿ã¯ *ç”Ÿæˆã‚‚è¦³å¯Ÿã‚‚å‡ºæ¥ãªã„!*
#+end_larger
#+end_alignright

** PU-Learning framework (Elkan & Noto, KDD 08')

*æ­£ä¾‹(positive) & æœªåˆ†é¡ä¾‹(unlabelled)ã‹ã‚‰ æ­£ä¾‹/è² ä¾‹ è­˜åˆ¥æ©Ÿã‚’å­¦ç¿’ã§ãã‚‹!*

+ æ­£ä¾‹: Training å…¥åŠ›. *è¦³å¯Ÿã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯å…¨ã¦æ­£ã—ã„ã€ä¿è¨¼æ¸ˆã¿*
+ æœªåˆ†é¡ä¾‹: *AAE ãŒç”Ÿæˆã™ã‚‹å…¨ã¦ã®å­ãƒãƒ¼ãƒ‰å€™è£œ*
  + ã©ã‚Œã‹ã¯æ­£ä¾‹ã€ã©ã‚Œã‹ã¯è² ä¾‹

#+begin_alignright
+ PUå­¦ç¿’ã§ AD ã‚’è¨“ç·´å¯èƒ½!
#+end_alignright

** å¾Œè€…é–¢æ•°

AAE ã§ *å­ãƒãƒ¼ãƒ‰å€™è£œã‚’åˆ—æŒ™*; AD/SDã§ *è² ä¾‹ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°*.

\begin{align*}
  Succ(s) &= \{t = apply(a,s) \; | \; a \in \{0\ldots 127\},\\
          & \qquad \land AD(s,t) \geq 0.5 \\
          & \qquad \land SD(t) \geq 0.5 \}
\end{align*}

# & \qquad \land SD(t) \geq 0.5 \\
# & \qquad \land Encode(Decode(s)) \equiv s \\
# & \qquad \land Apply(Action(t,s),s) \equiv t \}

å¾Œè€…çŠ¶æ…‹ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°ãŒæ‰‹ã«å…¥ã£ãŸãŸã‚ã€
å¤å…¸çš„ãªè¨˜å·çš„å‰æ–¹æ¢ç´¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  (A*, Dijkstra etc.) ãŒä½¿ç”¨å¯èƒ½

* Planning using AMA_2                                             :noexport:

Using a symbolic forward-search planner

+ Effects/preconditions are embedded in NNs, but there are *discrete action labels*
+ Simple $A^*$ with *goal-count* heuristics
  + The number of different bits from the goal

* AMA_2 Experiments 1

AAE ã¨ AD ã‚’ä½¿ã£ã¦ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†ã“ã¨ã¯å¯èƒ½?

+ ãã‚Œãã‚Œã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã”ã¨ã« *100å•* å•é¡Œã‚’ç”Ÿæˆ
  + åˆæœŸçŠ¶æ…‹ã¯ã‚´ãƒ¼ãƒ«ã‹ã‚‰ è‡ªå·±å›é¿ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ã§ç”Ÿæˆ
  + (benchmark A) 7æ­©
  + (benchmark B) 14æ­©
+ 180 sec. time limit

# The failures are due to timeouts
# (the successor function requires many calls to the feedforward neural nets,
#  resulting in a very slow node generation).

# We next examine the accuracy of the AD and SD (\reftbl{tab:aae-results}).
# We measured the type-1/2 errors for the valid and invalid transitions (for AD) and states (SD).
# Low errors show that our networks successfully learned the action models.

** Results

Noise are applied to the planning inputs (init/goal images)

G: Gaussian noise, s/p: salt/pepper noise

+ *Easy instances: Majority of instances are solved*
+ *Harder instances: Still many instances are solved*


|   | /          |   < |     |   > |   < |    |   > |
|   | step       |   7 |   7 |   7 |  14 | 14 |  14 |
|   | noise      | std |   G | s/p | std |  G | s/p |
|---+------------+-----+-----+-----+-----+----+-----|
|   | MNIST      |  72 |  64 |  64 |   6 |  4 |   3 |
|   | Mandrill   | 100 | 100 | 100 |   9 | 14 |  14 |
|   | Spider     |  94 |  99 |  98 |  29 | 36 |  38 |
|   | LightsOut  | 100 |  99 | 100 |  59 | 60 |  51 |
|   | Twisted LO |  96 |  65 |  98 |  75 | 68 |  72 |
| / | Hanoi      |  37 |  44 |  39 |  15 | 18 |  17 |

* AMA_2 Experiments 2                                              :noexport:

How accurate are Action Discriminators and State Discriminators?


#+begin_container-fluid
#+begin_row-fluid
#+begin_span7
Measure the type-1 / type-2 error in %

#+begin_smaller
|          |    SD |    SD |   |    AD |    AD |   AD |   AD |
|          | type1 | type2 |   | type1 | type2 | 2/SD |  2/V |
|----------+-------+-------+---+-------+-------+------+------|
| MNIST    |  0.09 | <0.01 |   |  1.55 |  14.9 | 6.15 | 6.20 |
| Mandrill | <0.01 | <0.01 |   |  1.10 |  16.6 | 2.93 | 2.94 |
| Spider   | <0.01 | <0.01 |   |  1.22 |  17.7 | 4.97 | 4.91 |
| L. Out   | <0.01 |   N/A |   |  0.03 |  1.64 | 1.64 | 1.64 |
| Twisted  | <0.01 |   N/A |   |  0.02 |  1.82 | 1.82 | 1.82 |
| Hanoi    |  0.03 | <0.01 |   |  0.25 |  3.50 | 3.79 | 4.07 |
#+end_smaller

#+end_span7
#+begin_span5
#+begin_smaller
+ (SD type-1) :: Generate all valid states and count the states misclassified as invalid.
+ (SD type-2) :: Generate reconstructable states, remove the valid states (w/ validator),
                 sample 30k states, and count the states misclassified as valid.
                 N/A means all reconstructable states were valid.
+ (AD type-1) :: Generate all valid transitions and count the number of misclassification.
+ (AD type-2) :: For 1000 randomly selected valid states, generate all successors,
                 remove the valid transitions (w/ validator), then count the transitions misclassified as valid.
+ (2/SD, 2/V) :: Same as Type-2, but ignore the transitions whose successors are
                 invalid according to SD or the validator.
#+end_smaller
#+end_span5
#+end_row-fluid
#+end_container-fluid

* AMA_2 Experiments 2                                              :noexport:

#+begin_container-fluid
#+begin_row-fluid
#+begin_span6
Action Discriminators ã®ç²¾åº¦ã¯?

Measure the type-1 / type-2 error in %

|   |          | type1 | type2 |
|---+----------+-------+-------|
|   | MNIST    |  1.55 |  6.15 |
|   | Mandrill |  1.10 |  2.93 |
|   | Spider   |  1.22 |  4.97 |
|   | L. Out   |  0.03 |  1.64 |
|   | Twisted  |  0.02 |  1.82 |
| / | Hanoi    |  0.25 |  3.79 |

#+end_span6
#+begin_span6
#+begin_smaller
+ (AD type-1) :: å…¨ã¦ã®æ­£ã—ã„çŠ¶æ…‹é·ç§»ã‚’ç”Ÿæˆã—ã€ADãŒè² ä¾‹ã¨ã—ãŸç‡
+ (AD type-2) :: ãƒ©ãƒ³ãƒ€ãƒ ã«çŠ¶æ…‹é·ç§»ã‚’ç”Ÿæˆã—ã€æ­£ã—ã„ã‚‚ã®ã‚’å–ã‚Šé™¤ãã€ADãŒæ­£ä¾‹ã¨ã—ãŸç‡
#+end_smaller
#+begin_larger
+ *ã‚ã‚‹ã¦ã„ã©æ­£ç¢º.*
#+end_larger
#+end_span6
#+end_row-fluid
#+end_container-fluid

# #+begin_larger
# #+begin_alignright
# + *Reasonably accurate.*
# #+end_alignright
# #+end_larger

* ã¾ã¨ã‚

+ *Latplan Architecture* 

  ã€€ã€€ç”»åƒã§ç¤ºã•ã‚ŒãŸç¾å®Ÿä¸–ç•Œã®å•é¡Œã‚’ *è‡ªåŠ›ã§è¨˜å·ãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›ã—* ã€è¨˜å·çš„æ¢ç´¢ã«ã‚ˆã£ã¦è§£ã
  # + å…¥åŠ› : Unlabelled pairs of images, initial image, goal image
  # + Output : Visualized plans to achieve the goal
+ *State AutoEncoder(SAE)* : */ç¾åœ¨çŠ¶æ…‹ã®ç”Ÿãƒ‡ãƒ¼ã‚¿/ â†” /å‘½é¡Œè¡¨ç¾/*
+ *Action AutoEncoder(AAE)* : */çŠ¶æ…‹é·ç§»/ â†” /ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚·ãƒ³ãƒœãƒ«/, /åŠ¹æœ/*
+ *Action Discriminator(AD)* : */çŠ¶æ…‹é·ç§»/ â†’ /çœŸå½å€¤/* , *PUå­¦ç¿’ã§è¨“ç·´*

#+begin_center
+ *å¤å…¸ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã§å¿…è¦ãªã‚·ãƒ³ãƒœãƒ«ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã®ã†ã¡ã€ï¼’ã¤ã‚’è§£æ±ºã—ãŸ!*
  | ã‚·ãƒ³ãƒœãƒ«ã®ç¨®é¡       |                              |
  |----------------------+------------------------------|
  | å‘½é¡Œå¤‰æ•°ã‚·ãƒ³ãƒœãƒ«     | *Solved!*                    |
  | ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚·ãƒ³ãƒœãƒ«   | *Solved!*                    |
  | ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚·ãƒ³ãƒœãƒ« | R-CNN (Computer Vision) etc? |
  | è¿°èªã‚·ãƒ³ãƒœãƒ«         | SCAN???                      |

  é€Ÿåº¦ã‚„ç²¾åº¦ãŒä»Šå¾Œã®èª²é¡Œ
#+end_center

** Future Work (å•é¡Œãƒ‰ãƒ¡ã‚¤ãƒ³)

LatPlan ã¯ ã‚ãã¾ã§ *ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£*

*SAE ã®å®Ÿè£…ã‚’å¤‰ãˆã‚Œã°(åŸç†çš„ã«ã¯)ç”»åƒä»¥å¤–ã®ä»»æ„ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã«å¯¾å¿œå¯èƒ½*

+ ãƒ†ã‚­ã‚¹ãƒˆç”¨ã®AE [Li et.al. 2015]ã€ éŸ³å£°ç”¨ã®AE [Deng, Li, et al. 2010]
+ æ”¹é€ ã—ã¦SAEã«ã™ã‚Œã°ãƒ»ãƒ»ãƒ»
  + *Here's an Apple, Here's a pen â†’ oh, ApplePen!*
+ SAEã‚’å­¦ç¿’ã—ã¦ãƒ—ãƒ©ãƒ³ãƒŠã§è§£ã

  â†’ *æ•°åƒã‚¹ãƒ†ãƒƒãƒ—ã® /è«–ç†çš„ãª/ è¨€èªãƒ¬ãƒ™ãƒ«æ¨è«– (åå°„ã§ã¯ãªã) ã‚’å¯èƒ½ã«*
  
  + ã“ã‚Œã¯ã€æœ¬è³ªçš„ã«è¿‘è¦–çœ¼çš„/è²ªæ¬²ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ(*å¼·åŒ–å­¦ç¿’ãªã©*)ã«ã¯ä¸å¯èƒ½

#+BEGIN_NOTE
 "A hierarchical neural autoencoder for paragraphs and documents." (2015)

 "Binary coding of speech spectrograms using a deep auto-encoder." (2010)
#+END_NOTE

# ** Future Work (Extended planning formalism)
# 
# + Latplan assumes nothing about the environment machinery (grids, movable tiles...)
# + Latplan assumes *fully-observable*, *deterministic* domains
# + Next step: *Extending Latplan to MDP, POMDP*
#   + Gumbel-Softmax layer â†’ just a Softmax layer? (probability)
#   + $AO^*$, $LAO^*$ algorithms for *optimal planning under uncertainty*
#     
# ** Other Future Works
# 
# Extracting rules from AAE/AD (discussed later)
# 
# Extracting much higher-order rule (predicates, HTN)

* *neural-symbolic* AI !

[[png:latplanlogo]]

* Appendix

Using the Remaining Time (Discussion)

** Konidaris et. al (2014, 2015): 

Structured input (e.g. *light switch*, *x/y-distance*) â†” unstructured image

Action Symbols (*move, interact*)

Just converting Semi-MDP /model/ to a PDDL /model/.

Could be used for extracting PDDL from AAE/AD

** NNs for solving combinatorial tasks:

TSP (Hopfield and Tank 1985)

Neurosolver for ToH (Bieszczad and Kuchar 2015)

*The input/output are symbolic.*

** Other Work Combining Symbolic Search and NNs

Embedded NNs *inside* a search to provide the *search control knowledge*

(i.e. node evaluation function)

Sliding-tile puzzle and Rubikâ€™s Cube (Arfaee et al. 2011)

Classical planning (Satzger and Kramer 2013)

The game of Go (AlphaGo, Silver et al. 2016)

** Deep Reinforcement Learning (DRL) (Mnih et al. 2015, DQN)

DQN assumes *predetermined action symbols* (â†‘â†“â†â†’+ buttons).

DQN *relies on simulators*. â†” Latplan *reverse-engineers a simulator*.

*DQN does not work* when it does not know *what action is even possible!*

** Other Interesting Systems

SCAN system (deepmind)

+ Maps *continuous* latent â†” *human-provided* symbolic vector

Î´-ILP (Inductive Logic Programming)

+ ILP robust to noise
  + Extracting rules from AAE/AD to form a PDDL?

** Why not individual pixels? Why DL?

*Systems based on individual pixels lack generalization*

+ Noise / variations can make the data entirely different

  [[png:results/noise]]

+ must acquire the *generalized features*

+ = a nonlinear function that recognize the entanglements between multiple pixels

** Learning vs Planning
  
 Main differences: Purposes and the abstraction layer

 #+begin_container-fluid
 #+begin_row-fluid
 #+begin_span6
 *Machine Learning, Neural Networks* 
 
 for *Recognition, Reflex*
 + *Subsymbolic å…¥åŠ›* (continuous)
   
   Images, Audio, unstructured text: 
 + *Soft Intelligence*:
   
   ã€€ */Reflex Agent/, /Immediate/ actions*
   #+begin_smaller
   *Pavlov's dog* : bell â†’ drool

   *Autonomous Driving* : Pedestrian â†’ Stop.

   *Machine Translation* : Sentence â†’ Sentence

   *Eval. Function for Go* : board â†’ win-rate
   #+end_smaller
   #+begin_larger
   â˜º Efficient 1-to-1 mapping
   
   â˜¹ Simple tasks
   #+end_larger
 #+end_span6
 #+begin_span6
 *Deliberation, Search*

 for *Planning, Game, Theorem Proving*
 + *Symbolic å…¥åŠ›/Output*
   
   Logic, objects, induction rules
 + *Hard Intelligence by Logic:*

   ã€€ */Multi-step/ strategies*
   
   #+begin_smaller
   *Rescue Robot* : actions â†’ help the surviver

   *Theorem Proving* : theorems â†’ QED

   *Compiler* : x86 instructions
   
   *Game of Go* : stones â†’ Win
   #+end_smaller
   #+begin_larger
   â˜º Ordering constraint + complex tasks
   #+end_larger
 #+end_span6
 #+end_row-fluid
 #+end_container-fluid

+ AlphaGo = Subsymbolic (DLNN eval. function) + Symbolic (MCTS)

** Human-Competitive Systems

 AlphaGo = Subsymbolic (NN eval. func) + Symbolic (MCTS)
 + However, *domain-specific* -- specialized in Go, "Grids" / "Stones" are known
 + *Huge expert trace DB* --- Not applicable when data are scarse (e.g. *space exploration*)
 + */Is supervised learning necessary for human?/*
  
   *True intelligence should search / collect data by itself*

 DQN = Subsymbolic (DLNN) + Reinforcement Learning (DLNN)

Domain-independent Atari Game solver (Invader, Packmanâ€¦), however:
 + RL Acting: Greedily follow the learned policy â†’ *no deliberation!*
 + You can survive most Atari games *by reflex*
  
 # å®Ÿéš› *Sokoban ãªã©è«–ç†æ€è€ƒã‚²ãƒ¼ãƒ ã§ã¯æ€§èƒ½ãŒæ‚ªã„* â†” å€‰åº«ç•ªã‚½ãƒ«ãƒ

** Latplan Advantages

#+begin_xlarge
*/Perception/* based on DLNN
#+end_xlarge

--- Robust systems augmented by the latest DL tech

#+begin_xlarge
*/Decision Making/* based on Classical Planning
#+end_xlarge

--- *Better Theoretical Guarantee than Reinforcement Learning*

#+begin_center
*Completeness* (Finds solution whenever possible), */Solution Optimality/*
#+end_center

--- *Decision Making Independent from Learning*

#+begin_center
*/Unsupervised/* (No data required), *Explainable* (Search by logic)
#+end_center

# ä»Šã¾ã§ã¯NNã¨ã®ç›¸æ€§ã‹ã‚‰å¼·åŒ–å­¦ç¿’ãŒå„ªå‹¢ã ã£ãŸãŒ *ã‚‚ã†ãã®å¿…è¦ã¯ãªã„*

*** When Latplan returns a /wrong/ solution?

 *Machine learning may contain errors* (convergence /only on/ $t\rightarrow \infty$, not on real time)

 + Images â†’ Fraud symbols/model/graph

 + *Optimal path on a fraud graph* or *graph disconnected*
  
   A* completeness, soundness, optimality (admissible heuristics) 

 + Fraud visualized plan (noisy) / no plan found

 #+begin_center
 #+begin_larger
 LatPlan may make */wrong observations/* but no */wrong decisions/*
 #+end_larger

 BTW, "correctness" is defined by error prone observations by humans anyways ...
 #+end_center

 #+begin_alignright
  (completeness, optimality) â†’ better reliablility than Reinforcement Learning
 #+end_alignright

*** Reinforcement Learning

Not only *perception* but *decision making also depends on training*

+ */Each training result does not have admissibility/*

+ */When the learned policy is wrong, the solution could be suboptimal/*

#+begin_quote
... AlphaGo was unprepared for Lee Sedolâ€™s Move 78 because it
didnâ€™t think that a human would ever play it.

#+begin_alignright
Cade Metz. "In Two Moves, that Redifined the Future." /Wired/, 2016
#+end_alignright
#+end_quote

#+begin_center
#+begin_larger
RL may make *wrong decisions*.
#+end_larger
#+end_center
** Future Work (SAE)

SAE can generate propositional symbols (state $s = \{q,r\ldots\}$)

+ 1st-order logic (predicate $p(a,b)$ )

+ We need *object recognition from images* (parameters $a,b$)

+ SAE with networks for object recognition (e.g. R-CNN) should achieve this

** Why symbols?

Symbols are strong abstraction mechanisms becasue

+ Meanings do not matter ::
     You do not have to understand it: Does a symbol $X$ mean an apple or a car?
 
     Logical reasoning can be performed by mechanical application of rules
     
     + Domain-independent planning : *mystery* vs *nomystery*

       Logistic domains where *symbol names are mangled* (truck â†’ shark)

+ Composable :: 
     A latent vector is a conjunction (and)
     
     Heuristic functions use modus ponens to derive guidance
